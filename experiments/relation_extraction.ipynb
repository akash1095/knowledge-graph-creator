{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:54:41.368866400Z",
     "start_time": "2026-01-08T17:54:40.222899800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "load_dotenv()\n",
    "\n",
    "from knowledge_graph_creator.llm.llm_inference import LLMInference, LLMConfig, GroqModel\n",
    "from knowledge_graph_creator.extractors.paper_relation_extractor import PaperRelationExtractor\n"
   ],
   "id": "591ddd1010185c7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asuji\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\knowledge-graph-creator-o7Cxat7M-py3.14\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:54:41.555883500Z",
     "start_time": "2026-01-08T17:54:41.387960500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize LLM client\n",
    "api_key = os.getenv(\"GROP_API_KEY_GRAPH\")\n",
    "llm_config = LLMConfig(model=GroqModel.LLAMA_8B, temperature=0.3)\n",
    "llm_client = LLMInference(api_key=api_key, config=llm_config)\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = PaperRelationExtractor(\n",
    "    uri=\"bolt://localhost:7687\", #os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USER\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    llm_client=llm_client,\n",
    "    min_delay=1\n",
    ")\n"
   ],
   "id": "df5946a525ffd6df",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:54:41.921432300Z",
     "start_time": "2026-01-08T17:54:41.574334400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 1: Get all triplets from database\n",
    "triplets = extractor.get_all_triplets(min_citation_count=0, min_year=2022)\n",
    "print(f\"Found {len(triplets)} triplets\")\n",
    "if triplets:\n",
    "    print(\"Sample triplet:\", triplets[0])\n"
   ],
   "id": "794a30dbe43019df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 569 triplets\n",
      "Sample triplet: {'tail_id': '85064a4b1b96863af4fccff9ad34ce484945ad7b', 'tail_title': 'Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces', 'tail_abstract': 'Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.', 'head_id': '6e17c6d0491342e040da8f9c7c6aa7ce0b9cd696', 'head_title': 'Varieties of Representations', 'head_abstract': '<jats:p/>'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:54:44.371302100Z",
     "start_time": "2026-01-08T17:54:42.754118300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 2: Extract relation with sample papers (mock data)\n",
    "sample_citing_paper = {\n",
    "    \"title\": \"Attention Is All You Need\",\n",
    "    \"abstract\": \"We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\",\n",
    "}\n",
    "\n",
    "sample_cited_paper = {\n",
    "    \"title\": \"Neural Machine Translation by Jointly Learning to Align and Translate\",\n",
    "    \"abstract\": \"We conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically search for parts of a source sentence that are relevant to predicting a target word.\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "result = extractor.extract_relation_with_structured_llm(\n",
    "    citing_paper=sample_citing_paper,\n",
    "    cited_paper=sample_cited_paper,\n",
    ")\n",
    "\n",
    "print(\"Extraction result:\")\n",
    "if result:\n",
    "    print(result.model_dump())\n",
    "else:\n",
    "    print(\"No result returned\")\n"
   ],
   "id": "856d33efed83049",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction result:\n",
      "{'relationships': [{'type': 'Requires', 'confidence': 'high', 'evidence': \"Paper 1 mentions 'a new simple network architecture, the Transformer' while Paper 2 introduces 'the Transformer model'\", 'explanation': 'Paper 1 depends on the Transformer model introduced in Paper 2 as a necessary foundation'}, {'type': 'Adapts-from', 'confidence': 'high', 'evidence': \"Paper 1 proposes 'a new simple network architecture' while Paper 2 extends the encoder-decoder architecture\", 'explanation': 'Paper 1 modifies the approach from Paper 2 to create a new network architecture'}], 'no_relationship_reason': None}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:53:44.429739800Z",
     "start_time": "2026-01-08T17:53:43.757839200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from knowledge_graph_creator.llm.schema import RelationshipAnalysis\n",
    "from knowledge_graph_creator.llm.prompts import EXTRACT_PROMPT\n",
    "\n",
    "prompt = EXTRACT_PROMPT.format(\n",
    "            source_title=sample_citing_paper.get(\"title\", \"N/A\"),\n",
    "            source_abstract=sample_citing_paper.get(\"abstract\", \"N/A\"),\n",
    "            target_title=sample_cited_paper.get(\"title\", \"N/A\"),\n",
    "            target_abstract=sample_cited_paper.get(\"abstract\", \"N/A\"),\n",
    "        )\n",
    "\n",
    "result = llm_client.structured_invoke(\n",
    "                    prompt=prompt,\n",
    "                    schema=RelationshipAnalysis,\n",
    "                )\n",
    "\n",
    "if isinstance(result, RelationshipAnalysis):\n",
    "    print(\"Structured extraction result:\")\n",
    "    print(result.model_dump())"
   ],
   "id": "9f23967147aa49f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured extraction result:\n",
      "{'relationships': [{'type': 'Extends', 'confidence': 'high', 'evidence': \"Paper 1 mentions 'a new simple network architecture, the Transformer, based solely on attention mechanisms' while Paper 2 introduces 'the basic encoder-decoder architecture', which Paper 1 extends by using attention mechanisms\", 'explanation': 'Paper 1 explicitly extends the methodology introduced in Paper 2 by using attention mechanisms'}, {'type': 'Requires', 'confidence': 'high', 'evidence': 'Paper 1 requires the attention mechanism, which was first introduced in Paper 2, to function', 'explanation': 'Paper 1 depends on the concepts/methods from Paper 2 as a necessary foundation'}], 'no_relationship_reason': None}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:54:55.727990800Z",
     "start_time": "2026-01-08T17:54:55.171794800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 3: Process single triplet from database\n",
    "if triplets:\n",
    "    single_triplet = triplets[0]\n",
    "    citing = {\n",
    "        \"title\": single_triplet[\"tail_title\"],\n",
    "        \"abstract\": single_triplet[\"tail_abstract\"],\n",
    "    }\n",
    "    cited = {\n",
    "        \"title\": single_triplet[\"head_title\"],\n",
    "        \"abstract\": single_triplet[\"head_abstract\"],\n",
    "    }\n",
    "\n",
    "    analysis = extractor.extract_relation_with_structured_llm(citing, cited)\n",
    "    if analysis:\n",
    "        print(\"Relationships found:\")\n",
    "        for rel in analysis.relationships:\n",
    "            print(f\"  - {rel.type} (confidence: {rel.confidence})\")\n",
    "            print(f\"    Evidence: {rel.evidence}\")\n"
   ],
   "id": "d94b5ef24d6ed0f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationships found:\n",
      "  - Requires (confidence: high)\n",
      "    Evidence: Paper 1 discusses the importance of representation spaces, which is a key concept in Paper 2\n",
      "  - Challenges (confidence: medium)\n",
      "    Evidence: Paper 1 suggests 'promising research directions from a representation space perspective', which could be seen as a challenge to the ideas presented in Paper 2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T05:42:47.652896900Z",
     "start_time": "2026-01-05T05:42:47.624729200Z"
    }
   },
   "cell_type": "code",
   "source": "analysis",
   "id": "355fcc3a235f85f0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:55:11.755432500Z",
     "start_time": "2026-01-08T17:55:04.053623100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 4: Process limited batch (first 3 triplets)\n",
    "limited_triplets = triplets[:3] if len(triplets) >= 3 else triplets\n",
    "\n",
    "results = []\n",
    "import time\n",
    "\n",
    "for idx, triplet in enumerate(limited_triplets):\n",
    "    citing = {\"title\": triplet[\"tail_title\"], \"abstract\": triplet[\"tail_abstract\"]}\n",
    "    cited = {\"title\": triplet[\"head_title\"], \"abstract\": triplet[\"head_abstract\"]}\n",
    "\n",
    "    print(f\"Processing {idx + 1}/{len(limited_triplets)}\")\n",
    "    analysis = extractor.extract_relation_with_structured_llm(citing, cited)\n",
    "\n",
    "    if analysis:\n",
    "        results.append({\n",
    "            \"citing_id\": triplet[\"tail_id\"],\n",
    "            \"cited_id\": triplet[\"head_id\"],\n",
    "            \"relationships\": [r.model_dump() for r in analysis.relationships],\n",
    "        })\n",
    "\n",
    "    time.sleep(2)  # Rate limiting\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} triplets successfully\")\n"
   ],
   "id": "647eb44e85a78736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/3\n",
      "Processing 2/3\n",
      "Processing 3/3\n",
      "\n",
      "Processed 3 triplets successfully\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T05:48:41.922743Z",
     "start_time": "2026-01-05T05:48:41.874597400Z"
    }
   },
   "cell_type": "code",
   "source": "limited_triplets[0]",
   "id": "3fb4ab3d93efdd73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tail_id': '85064a4b1b96863af4fccff9ad34ce484945ad7b',\n",
       " 'tail_title': 'Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces',\n",
       " 'tail_abstract': 'Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.',\n",
       " 'head_id': '6e17c6d0491342e040da8f9c7c6aa7ce0b9cd696',\n",
       " 'head_title': 'Varieties of Representations',\n",
       " 'head_abstract': '<jats:p/>'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7654594956e57975"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:56:06.637229700Z",
     "start_time": "2026-01-08T17:56:04.723738200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test save_relationships with first triplet\n",
    "if limited_triplets and results:\n",
    "    # Use the first triplet and its analysis\n",
    "    first_triplet = limited_triplets[0]\n",
    "\n",
    "    # Re-extract or use existing analysis\n",
    "    citing = {\"title\": first_triplet[\"tail_title\"], \"abstract\": first_triplet[\"tail_abstract\"]}\n",
    "    cited = {\"title\": first_triplet[\"head_title\"], \"abstract\": first_triplet[\"head_abstract\"]}\n",
    "\n",
    "    analysis = extractor.extract_relation_with_structured_llm(citing, cited)\n",
    "\n",
    "    if analysis:\n",
    "        extractor.save_relationships(\n",
    "            citing_id=first_triplet[\"tail_id\"],\n",
    "            cited_id=first_triplet[\"head_id\"],\n",
    "            analysis=analysis\n",
    "        )\n",
    "        print(f\"Saved relationships for {first_triplet['tail_id']} -> {first_triplet['head_id']}\")\n",
    "        print(f\"Relationships: {[r.type for r in analysis.relationships]}\")\n",
    "    else:\n",
    "        print(\"No analysis to save\")"
   ],
   "id": "7017b8e40633f906",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved relationships for 85064a4b1b96863af4fccff9ad34ce484945ad7b -> 6e17c6d0491342e040da8f9c7c6aa7ce0b9cd696\n",
      "Relationships: ['Requires', 'Adapts-from']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T17:58:32.376586800Z",
     "start_time": "2026-01-08T17:56:49.284282900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 5: Full pipeline with save (use with caution - writes to DB)\n",
    "# Uncomment to run\n",
    "full_results = extractor.process_all_triplets(min_citation_count=5, min_year=2023)\n",
    "print(f\"Processed {len(full_results)} triplets\")\n"
   ],
   "id": "3af5239da2bc6c88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2026-01-08 23:26:49.449\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m140\u001B[0m - \u001B[1mFound 235 triplets to process\u001B[0m\n",
      "\u001B[32m2026-01-08 23:26:49.450\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 1/235: 9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6 -> 8bbdf825e6ccd197adfff5ebeecc9a5a5210e02f\u001B[0m\n",
      "\u001B[32m2026-01-08 23:26:51.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 2/235: 27c302b8e29cbd7981587765c388e85cad143a8b -> 4085a5cf49c193fe3d3ff19ff2d696fe20a5a596\u001B[0m\n",
      "\u001B[32m2026-01-08 23:26:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 3/235: 65947afa8f1a6673ae9d4932b1262dca776c097c -> 9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6\u001B[0m\n",
      "\u001B[32m2026-01-08 23:26:55.333\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 4/235: 180fb9d10c835b6defac94fe727a98def1d9f4ac -> 9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6\u001B[0m\n",
      "\u001B[32m2026-01-08 23:27:10.478\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 5/235: 5fa9bcf38bcf71d9b0dd27b7c84023f1aa8b0f7e -> a0c2052ea02e1916263841db5b9ca3b13e10ccd1\u001B[0m\n",
      "\u001B[32m2026-01-08 23:27:28.530\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 6/235: a89fe3c6749c79354b30a154c6298a7ff2bec9d6 -> 389045fdb1f14faece3cd809b2ec4744c5d89433\u001B[0m\n",
      "\u001B[32m2026-01-08 23:27:46.555\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 7/235: 97abfd909837be85fb747eb9240b69795b005353 -> 389045fdb1f14faece3cd809b2ec4744c5d89433\u001B[0m\n",
      "\u001B[32m2026-01-08 23:28:02.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 8/235: 3c2e35594593e07427c39f66baf2e69d09151eb0 -> bf8491bef353df126e2306ad2fe4b898697b906a\u001B[0m\n",
      "\u001B[32m2026-01-08 23:28:20.563\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m153\u001B[0m - \u001B[1mProcessing 9/235: 73152684dc8d3c41d1c9a1aa8e8b14c21af5fc3e -> bf8491bef353df126e2306ad2fe4b898697b906a\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T05:50:59.341901900Z",
     "start_time": "2026-01-05T05:50:59.314300900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cleanup\n",
    "extractor.close()"
   ],
   "id": "3340c27d2c0263c5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2253fc1c67bc34a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
