{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T09:28:42.581629500Z",
     "start_time": "2026-01-19T09:28:41.591710800Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from dotenv import load_dotenv\n",
    "from knowledge_graph_creator.orchestrator import PDFToKnowledgeGraphOrchestrator\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T09:28:42.613478600Z",
     "start_time": "2026-01-19T09:28:42.581629500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orchestrator = PDFToKnowledgeGraphOrchestrator(\n",
    "    neo4j_uri=os.getenv(\"NEO4J_URI\"),\n",
    "    neo4j_user=os.getenv(\"NEO4J_USER\"),\n",
    "    neo4j_password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    ss_api_key=os.getenv(\"SS_API_KEY\"),\n",
    ")"
   ],
   "id": "67c48ded63848c34",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-19T09:28:43.245223300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process PDF and build knowledge graph\n",
    "successful, unsuccessful = orchestrator.process_title_to_graph_with_network(\n",
    "    parent_paper_title=\"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing\",\n",
    "    citation_network_type=\"citations\",\n",
    "    include_citations=True,\n",
    "    max_citations_per_paper=100,\n",
    "    rate_limit_delay=0.5,\n",
    "    publication_year=\"2021:2025\",\n",
    "\n",
    ")"
   ],
   "id": "792ec4bef816cb74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2026-01-19 14:58:45.703\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.orchestrator\u001B[0m:\u001B[36mprocess_title_to_graph_with_network\u001B[0m:\u001B[36m232\u001B[0m - \u001B[1mParent paper Details: 28692beece311a90f5fa1ca2ec9d0c2ce293d069 - Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing - Primary Author -Pengfei Liu\u001B[0m\n",
      "\u001B[32m2026-01-19 14:58:48.610\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.orchestrator\u001B[0m:\u001B[36mget_parper_to_process\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mNumber of Citation collections: 100\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding parent paper: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2026-01-19 14:58:49.845\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 28692beece311a90f5fa1ca2ec9d0c2ce293d069\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 100 references...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding references:   0%|\u001B[32m          \u001B[0m| 0/100 [00:00<?, ?it/s]\u001B[32m2026-01-19 14:58:51.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 85bdbc26b7603f0dc6889b0042ab60e27067fd4e\u001B[0m\n",
      "\n",
      "Citations for 85bdbc26: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   1%|\u001B[32m          \u001B[0m| 1/100 [00:05<09:03,  5.49s/it]\u001B[32m2026-01-19 14:58:58.327\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c7ec419c6ac8a7d27b7398f356acf9c01b1bafab\u001B[0m\n",
      "\n",
      "Citations for c7ec419c: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   2%|\u001B[32m▏         \u001B[0m| 2/100 [00:10<08:33,  5.24s/it]\u001B[32m2026-01-19 14:59:01.166\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: d18c98354234ad72dc13c5ec9ed8abdd9200f33a\u001B[0m\n",
      "\n",
      "Citations for d18c9835: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   3%|\u001B[32m▎         \u001B[0m| 3/100 [00:13<06:33,  4.06s/it]\u001B[32m2026-01-19 14:59:03.290\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 21727373bf6027238cb675724fb0b1c0117d8c16\u001B[0m\n",
      "\n",
      "Citations for 21727373: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   4%|\u001B[32m▍         \u001B[0m| 4/100 [00:15<05:17,  3.31s/it]\u001B[32m2026-01-19 14:59:05.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7514e48df214abc6c7b99048812dea1b99777f69\u001B[0m\n",
      "\n",
      "Citations for 7514e48d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   5%|\u001B[32m▌         \u001B[0m| 5/100 [00:19<05:50,  3.69s/it]\u001B[32m2026-01-19 14:59:09.812\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5c8b0f792424b759dda0c2235c9323ad0eb61316\u001B[0m\n",
      "\n",
      "Citations for 5c8b0f79: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   6%|\u001B[32m▌         \u001B[0m| 6/100 [00:23<05:42,  3.64s/it]\u001B[32m2026-01-19 14:59:13.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: ca0b47f824a54695880adfdb2404fac8ff7f896c\u001B[0m\n",
      "\n",
      "Citations for ca0b47f8: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   7%|\u001B[32m▋         \u001B[0m| 7/100 [00:26<05:11,  3.35s/it]\u001B[32m2026-01-19 14:59:15.948\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 82be906a8aa6895796b2b9afc42953dd3ae2392e\u001B[0m\n",
      "\n",
      "Citations for 82be906a: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   8%|\u001B[32m▊         \u001B[0m| 8/100 [00:29<05:02,  3.29s/it]\u001B[32m2026-01-19 14:59:19.271\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 722ccaa0a103522d7c9bf9f24ba3dca72bee90d4\u001B[0m\n",
      "\n",
      "Citations for 722ccaa0: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:   9%|\u001B[32m▉         \u001B[0m| 9/100 [00:33<05:41,  3.75s/it]\u001B[32m2026-01-19 14:59:24.477\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 3e340a76b8fa3b8fba3b6bdfa11d7eac763258ef\u001B[0m\n",
      "\n",
      "Citations for 3e340a76: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  10%|\u001B[32m█         \u001B[0m| 10/100 [00:37<05:38,  3.76s/it]\u001B[32m2026-01-19 14:59:28.385\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 50ec5a3f2b4175e9d2ae1fbfacdddaaaff937ab9\u001B[0m\n",
      "\n",
      "Citations for 50ec5a3f: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  11%|\u001B[32m█         \u001B[0m| 11/100 [00:40<05:00,  3.38s/it]\u001B[32m2026-01-19 14:59:30.302\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 776a462ddbe3c155898e8e738d43da73c0a9a84c\u001B[0m\n",
      "\n",
      "Citations for 776a462d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  12%|\u001B[32m█▏        \u001B[0m| 12/100 [00:42<04:36,  3.14s/it]\u001B[32m2026-01-19 14:59:32.896\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 816d3fc10eb9ca395b7c5b2781ae3d84956c1898\u001B[0m\n",
      "\n",
      "Citations for 816d3fc1: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  13%|\u001B[32m█▎        \u001B[0m| 13/100 [00:45<04:19,  2.98s/it]\u001B[32m2026-01-19 14:59:35.478\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: b5f46a990b5c9d8fe1679419d5cafc7dfb5e11b1\u001B[0m\n",
      "\n",
      "Citations for b5f46a99: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  14%|\u001B[32m█▍        \u001B[0m| 14/100 [00:47<03:54,  2.73s/it]\u001B[32m2026-01-19 14:59:37.787\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 179ed83ab09e0bb2473c5c5f6ad8bb9ec06a8c38\u001B[0m\n",
      "\n",
      "Citations for 179ed83a: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  15%|\u001B[32m█▌        \u001B[0m| 15/100 [00:49<03:36,  2.54s/it]\u001B[32m2026-01-19 14:59:40.696\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e7c1852b79c3ffe5a731aef1f4b3a289efdc76e7\u001B[0m\n",
      "\n",
      "Citations for e7c1852b: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  16%|\u001B[32m█▌        \u001B[0m| 16/100 [00:52<03:40,  2.63s/it]\u001B[32m2026-01-19 14:59:42.580\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e0d5a840d7e4a5b385e9bf1de72abb9aeeb5e5df\u001B[0m\n",
      "\n",
      "Citations for e0d5a840: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  17%|\u001B[32m█▋        \u001B[0m| 17/100 [00:54<03:27,  2.50s/it]\u001B[32m2026-01-19 14:59:44.737\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e8323a8348350a5a624941425f81643041bf177d\u001B[0m\n",
      "\n",
      "Citations for e8323a83: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  18%|\u001B[32m█▊        \u001B[0m| 18/100 [00:56<03:10,  2.32s/it]\u001B[32m2026-01-19 14:59:46.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: d2d87f09499ba002577e6128ca70d38dd2aaa3ad\u001B[0m\n",
      "\n",
      "Citations for d2d87f09: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  19%|\u001B[32m█▉        \u001B[0m| 19/100 [00:59<03:16,  2.42s/it]\u001B[32m2026-01-19 14:59:49.374\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 19f03b5f9e63519a573012ab47a5686d0d473219\u001B[0m\n",
      "\n",
      "Citations for 19f03b5f: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  20%|\u001B[32m██        \u001B[0m| 20/100 [01:02<03:31,  2.65s/it]\u001B[32m2026-01-19 14:59:52.384\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: cf86a523423540cb6dd16a687c88e5bcbeb2c4e8\u001B[0m\n",
      "\n",
      "Citations for cf86a523: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  21%|\u001B[32m██        \u001B[0m| 21/100 [01:03<02:56,  2.24s/it]\u001B[32m2026-01-19 14:59:53.736\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 0f64cb176b041a36a6c8e902b8f421d0bf048c84\u001B[0m\n",
      "\n",
      "Citations for 0f64cb17: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  22%|\u001B[32m██▏       \u001B[0m| 22/100 [01:05<02:42,  2.09s/it]\u001B[32m2026-01-19 14:59:55.564\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 9c6f320df203374919558d17b1037c336bf8f598\u001B[0m\n",
      "\n",
      "Citations for 9c6f320d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  23%|\u001B[32m██▎       \u001B[0m| 23/100 [01:10<03:40,  2.86s/it]\u001B[32m2026-01-19 15:00:00.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 8d0e591c47f020528dfc36ddff605bd1592ccd85\u001B[0m\n",
      "\n",
      "Citations for 8d0e591c: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  24%|\u001B[32m██▍       \u001B[0m| 24/100 [01:11<03:07,  2.46s/it]\u001B[32m2026-01-19 15:00:01.748\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 14f7443868dbe1438eee3b8b2dbff368cf730f06\u001B[0m\n",
      "\n",
      "Citations for 14f74438: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  25%|\u001B[32m██▌       \u001B[0m| 25/100 [01:13<02:50,  2.27s/it]\u001B[32m2026-01-19 15:00:03.585\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7ff97fc0983ca9536ed283249b5ef2e3c8196e2f\u001B[0m\n",
      "\n",
      "Citations for 7ff97fc0:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:05.327\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: b478f9692aaf9d74dcd0907d1c31bb2a3d012cca\u001B[0m\n",
      "\n",
      "Citations for 7ff97fc0: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  3.11it/s]\u001B[A\n",
      "Adding references:  26%|\u001B[32m██▌       \u001B[0m| 26/100 [01:15<02:41,  2.19s/it]\u001B[32m2026-01-19 15:00:05.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c4b1e2439c3d521d8597d10d07708981a2ce29d8\u001B[0m\n",
      "\n",
      "Citations for c4b1e243: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  27%|\u001B[32m██▋       \u001B[0m| 27/100 [01:20<03:36,  2.96s/it]\u001B[32m2026-01-19 15:00:10.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 834b94fcace9b979f7c5049a19999bf6ff5eec06\u001B[0m\n",
      "\n",
      "Citations for 834b94fc: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  28%|\u001B[32m██▊       \u001B[0m| 28/100 [01:22<03:10,  2.64s/it]\u001B[32m2026-01-19 15:00:12.180\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 8aabe41213e95682ff40b2fd20ecd9d92eecb9cd\u001B[0m\n",
      "\n",
      "Citations for 8aabe412: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  29%|\u001B[32m██▉       \u001B[0m| 29/100 [01:24<03:05,  2.61s/it]\u001B[32m2026-01-19 15:00:14.734\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: fbca0c2ec5425bbd8dc4898d684c909a58dab1de\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:   0%|\u001B[32m          \u001B[0m| 0/11 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:16.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a0e649b7b3ddb634aa5b54a60071312d6d22fc93\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:   9%|\u001B[32m▉         \u001B[0m| 1/11 [00:00<00:03,  2.68it/s]\u001B[A\u001B[32m2026-01-19 15:00:16.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 2425b927c4f653685cfc1f6f1addddeb43602f0d\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  18%|\u001B[32m█▊        \u001B[0m| 2/11 [00:00<00:02,  4.05it/s]\u001B[A\u001B[32m2026-01-19 15:00:16.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: d245095e76711783437c4181c3246d111c7673ff\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  27%|\u001B[32m██▋       \u001B[0m| 3/11 [00:00<00:01,  5.02it/s]\u001B[A\u001B[32m2026-01-19 15:00:17.079\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e6f07c700eb2fe958e0d6cccd349851f01a55f81\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  36%|\u001B[32m███▋      \u001B[0m| 4/11 [00:00<00:01,  4.47it/s]\u001B[A\u001B[32m2026-01-19 15:00:17.335\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: ae7da41c02bf97ec09db5aba3677a0cd23e6d23b\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  45%|\u001B[32m████▌     \u001B[0m| 5/11 [00:01<00:01,  4.23it/s]\u001B[A\u001B[32m2026-01-19 15:00:17.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 763b1b2530b307716985145d7d82d9fa6274f534\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  55%|\u001B[32m█████▍    \u001B[0m| 6/11 [00:01<00:01,  4.66it/s]\u001B[A\u001B[32m2026-01-19 15:00:17.767\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 9259d06eeaae42b05ad22ba76f0a1cbb216ad63a\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  64%|\u001B[32m██████▎   \u001B[0m| 7/11 [00:01<00:00,  4.34it/s]\u001B[A\u001B[32m2026-01-19 15:00:18.051\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 9daa5bec09f77aa9423a9c9f18585c05e1cc80e4\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  73%|\u001B[32m███████▎  \u001B[0m| 8/11 [00:01<00:00,  4.04it/s]\u001B[A\u001B[32m2026-01-19 15:00:18.551\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 542016b7b45b8be6d30994233191b8364767cb05\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  82%|\u001B[32m████████▏ \u001B[0m| 9/11 [00:02<00:00,  3.07it/s]\u001B[A\u001B[32m2026-01-19 15:00:18.707\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 8396c663cae6727bfa7d81b6a16e055bdf47e1b0\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e:  91%|\u001B[32m█████████ \u001B[0m| 10/11 [00:02<00:00,  3.65it/s]\u001B[A\u001B[32m2026-01-19 15:00:19.318\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5d95d2b9bc203447000bd201ceabe67404eedeeb\u001B[0m\n",
      "\n",
      "Citations for fbca0c2e: 100%|\u001B[32m██████████\u001B[0m| 11/11 [00:03<00:00,  2.66it/s]\u001B[A\n",
      "Adding references:  30%|\u001B[32m███       \u001B[0m| 30/100 [01:29<03:48,  3.27s/it]\u001B[32m2026-01-19 15:00:19.572\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 396597163efa3d5e6e8baf7df7df64f41246fabb\u001B[0m\n",
      "\n",
      "Citations for 39659716: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  31%|\u001B[32m███       \u001B[0m| 31/100 [01:31<03:15,  2.83s/it]\u001B[32m2026-01-19 15:00:21.345\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 91c7d2a1dbeca44b2728991475aa7e56d1c033c6\u001B[0m\n",
      "\n",
      "Citations for 91c7d2a1:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:22.763\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: bd5f53db73a367b37fd79e361962f673b38df759\u001B[0m\n",
      "\n",
      "Citations for 91c7d2a1: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  3.77it/s]\u001B[A\n",
      "Adding references:  32%|\u001B[32m███▏      \u001B[0m| 32/100 [01:32<02:47,  2.47s/it]\u001B[32m2026-01-19 15:00:22.973\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: f0c73a036fe30a446adf9c8a22f448cf7c5947db\u001B[0m\n",
      "\n",
      "Citations for f0c73a03: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  33%|\u001B[32m███▎      \u001B[0m| 33/100 [01:34<02:23,  2.14s/it]\u001B[32m2026-01-19 15:00:24.329\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 30ac04678afecdd79354e6c7324bf2302b2c8d09\u001B[0m\n",
      "\n",
      "Citations for 30ac0467: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  34%|\u001B[32m███▍      \u001B[0m| 34/100 [01:36<02:18,  2.10s/it]\u001B[32m2026-01-19 15:00:26.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 280e7f7beed86af49be0679e3638c9971dafce70\u001B[0m\n",
      "\n",
      "Citations for 280e7f7b: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  35%|\u001B[32m███▌      \u001B[0m| 35/100 [01:40<02:59,  2.76s/it]\u001B[32m2026-01-19 15:00:30.639\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 571921e7d0d0a4927cc7fe73ed06cf9e4f8ba15a\u001B[0m\n",
      "\n",
      "Citations for 571921e7: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  36%|\u001B[32m███▌      \u001B[0m| 36/100 [01:43<02:58,  2.79s/it]\u001B[32m2026-01-19 15:00:33.474\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: f5cb1bbb0cb501553938f2e1beea37729f3f85e1\u001B[0m\n",
      "\n",
      "Citations for f5cb1bbb: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  37%|\u001B[32m███▋      \u001B[0m| 37/100 [01:44<02:31,  2.40s/it]\u001B[32m2026-01-19 15:00:34.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7acb1efd2d692f92d22519add6e54e515c289dfe\u001B[0m\n",
      "\n",
      "Citations for 7acb1efd: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  38%|\u001B[32m███▊      \u001B[0m| 38/100 [01:47<02:28,  2.39s/it]\u001B[32m2026-01-19 15:00:37.314\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a71c05c3a6e7b6ecaa4f2446920dfd1acaaefd39\u001B[0m\n",
      "\n",
      "Citations for a71c05c3: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  39%|\u001B[32m███▉      \u001B[0m| 39/100 [01:48<02:08,  2.11s/it]\u001B[32m2026-01-19 15:00:38.861\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: f66ea6500dce8124b2447baf5c6dd03036f26d88\u001B[0m\n",
      "\n",
      "Citations for f66ea650: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  40%|\u001B[32m████      \u001B[0m| 40/100 [01:50<02:03,  2.05s/it]\u001B[32m2026-01-19 15:00:40.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: bfaf2667e0383c7c12989abf73b9c50c0152ac13\u001B[0m\n",
      "\n",
      "Citations for bfaf2667: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  41%|\u001B[32m████      \u001B[0m| 41/100 [01:53<02:10,  2.21s/it]\u001B[32m2026-01-19 15:00:43.268\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: cc2297bc1a5bea289425e2e363ce266ec93f3183\u001B[0m\n",
      "\n",
      "Citations for cc2297bc: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  42%|\u001B[32m████▏     \u001B[0m| 42/100 [01:54<01:56,  2.00s/it]\u001B[32m2026-01-19 15:00:44.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 99a0c944b22f4b051653cd45ffb9984fa8a0d7c4\u001B[0m\n",
      "\n",
      "Citations for 99a0c944: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  43%|\u001B[32m████▎     \u001B[0m| 43/100 [01:56<01:45,  1.86s/it]\u001B[32m2026-01-19 15:00:46.323\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: b7fa0bbeca78ab47918e77accdd26cdb03d680a8\u001B[0m\n",
      "\n",
      "Citations for b7fa0bbe:   0%|\u001B[32m          \u001B[0m| 0/2 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:48.294\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5d6495ed71fb69dc2afbe547aa3dd68d9aa0637e\u001B[0m\n",
      "\n",
      "Citations for b7fa0bbe:  50%|\u001B[32m█████     \u001B[0m| 1/2 [00:00<00:00,  2.26it/s]\u001B[A\u001B[32m2026-01-19 15:00:48.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e0815f25b4ca2cb009621d9210a2882ecff74907\u001B[0m\n",
      "\n",
      "Citations for b7fa0bbe: 100%|\u001B[32m██████████\u001B[0m| 2/2 [00:00<00:00,  2.66it/s]\u001B[A\n",
      "Adding references:  44%|\u001B[32m████▍     \u001B[0m| 44/100 [01:58<01:55,  2.05s/it]\u001B[32m2026-01-19 15:00:48.976\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7ba518bc3062c42c58830c321188ed398fd9bb2a\u001B[0m\n",
      "\n",
      "Citations for 7ba518bc:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:50.838\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e024fd10ad5302efda3d94b2fae1264037af50ac\u001B[0m\n",
      "\n",
      "Citations for 7ba518bc: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  7.79it/s]\u001B[A\n",
      "Adding references:  45%|\u001B[32m████▌     \u001B[0m| 45/100 [02:01<01:55,  2.09s/it]\u001B[32m2026-01-19 15:00:51.086\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 0036962d1816ee86b47b735025ddb2a5b97090f9\u001B[0m\n",
      "\n",
      "Citations for 0036962d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  46%|\u001B[32m████▌     \u001B[0m| 46/100 [02:02<01:49,  2.04s/it]\u001B[32m2026-01-19 15:00:52.926\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 414a1d7361f29122da81e8e70c8fb1f7be3e1653\u001B[0m\n",
      "\n",
      "Citations for 414a1d73: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  47%|\u001B[32m████▋     \u001B[0m| 47/100 [02:04<01:41,  1.92s/it]\u001B[32m2026-01-19 15:00:54.709\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 25031d35844b91f141b13db7b4b55aa287fb396a\u001B[0m\n",
      "\n",
      "Citations for 25031d35: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  48%|\u001B[32m████▊     \u001B[0m| 48/100 [02:06<01:41,  1.94s/it]\u001B[32m2026-01-19 15:00:56.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 1caf98e62d210eb6d3f054f9e82061018a89b758\u001B[0m\n",
      "\n",
      "Citations for 1caf98e6: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  49%|\u001B[32m████▉     \u001B[0m| 49/100 [02:08<01:34,  1.85s/it]\u001B[32m2026-01-19 15:00:58.138\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: abc470db9694e9bc7761795ba406f0a22984dbcd\u001B[0m\n",
      "\n",
      "Citations for abc470db:   0%|\u001B[32m          \u001B[0m| 0/6 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:00:59.617\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 833c3b61c12609b5b3eb41dc567d7e67e7025bb9\u001B[0m\n",
      "\n",
      "Citations for abc470db:  17%|\u001B[32m█▋        \u001B[0m| 1/6 [00:00<00:00,  7.68it/s]\u001B[A\u001B[32m2026-01-19 15:00:59.698\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: e326bfe505b32d87479a4f56d7799def195f34da\u001B[0m\n",
      "\u001B[32m2026-01-19 15:00:59.799\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: ef6119bf62bb47dbd907965f593eab8f9855d189\u001B[0m\n",
      "\n",
      "Citations for abc470db:  50%|\u001B[32m█████     \u001B[0m| 3/6 [00:00<00:00,  9.80it/s]\u001B[A\u001B[32m2026-01-19 15:00:59.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c6b0e90a491590f7682fb4b6788f21b0186b34ed\u001B[0m\n",
      "\u001B[32m2026-01-19 15:01:00.017\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 4fffab3413d625c27436fee5c056dc0d56dcca2e\u001B[0m\n",
      "\n",
      "Citations for abc470db:  83%|\u001B[32m████████▎ \u001B[0m| 5/6 [00:00<00:00,  9.39it/s]\u001B[A\u001B[32m2026-01-19 15:01:00.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 321ac5cb1cd48b93d42fe9531de3789441e56807\u001B[0m\n",
      "\n",
      "Adding references:  50%|\u001B[32m█████     \u001B[0m| 50/100 [02:10<01:35,  1.92s/it]\u001B[32m2026-01-19 15:01:00.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 678d85516e8b6cdcb5902e14400d689956c2db92\u001B[0m\n",
      "\n",
      "Citations for 678d8551: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  51%|\u001B[32m█████     \u001B[0m| 51/100 [02:11<01:26,  1.76s/it]\u001B[32m2026-01-19 15:01:01.767\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a8c84e4e5b0ba2d2445100c43f7be2735f65c247\u001B[0m\n",
      "\n",
      "Citations for a8c84e4e:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:01:03.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: fb5f1798f56614398c73462a638bb152ea5015ce\u001B[0m\n",
      "\n",
      "Citations for a8c84e4e: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  2.06it/s]\u001B[A\n",
      "Adding references:  52%|\u001B[32m█████▏    \u001B[0m| 52/100 [02:13<01:26,  1.81s/it]\u001B[32m2026-01-19 15:01:03.854\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a70f9454f3505d486813447c4a22a6347b75ed72\u001B[0m\n",
      "\n",
      "Citations for a70f9454: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  53%|\u001B[32m█████▎    \u001B[0m| 53/100 [02:15<01:28,  1.88s/it]\u001B[32m2026-01-19 15:01:05.554\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 506a46319dacc8f1fdd5961c8d1e5979fd8086ea\u001B[0m\n",
      "\n",
      "Citations for 506a4631: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  54%|\u001B[32m█████▍    \u001B[0m| 54/100 [02:16<01:19,  1.72s/it]\u001B[32m2026-01-19 15:01:06.956\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 56c986d0b48d401cb409ec6f0a0e2cd57f9cb52c\u001B[0m\n",
      "\n",
      "Citations for 56c986d0: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  55%|\u001B[32m█████▌    \u001B[0m| 55/100 [02:18<01:11,  1.59s/it]\u001B[32m2026-01-19 15:01:08.238\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 1a5408d9234b183a26399243debe76e4a8166e0d\u001B[0m\n",
      "\n",
      "Citations for 1a5408d9: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  56%|\u001B[32m█████▌    \u001B[0m| 56/100 [02:19<01:11,  1.62s/it]\u001B[32m2026-01-19 15:01:10.092\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 645c5d88d4900b7b0716c0a0ef5f888fdb91e9ab\u001B[0m\n",
      "\n",
      "Citations for 645c5d88: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  57%|\u001B[32m█████▋    \u001B[0m| 57/100 [02:21<01:07,  1.56s/it]\u001B[32m2026-01-19 15:01:11.578\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 13dbccb1d3db5b1ba25a18f4351a43e2de28ca3f\u001B[0m\n",
      "\n",
      "Citations for 13dbccb1: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  58%|\u001B[32m█████▊    \u001B[0m| 58/100 [02:22<01:04,  1.54s/it]\u001B[32m2026-01-19 15:01:12.921\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: f0417bc9c314055f7a8cc85b5cffa27a25b2a3e7\u001B[0m\n",
      "\n",
      "Citations for f0417bc9: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  59%|\u001B[32m█████▉    \u001B[0m| 59/100 [02:24<01:00,  1.48s/it]\u001B[32m2026-01-19 15:01:14.238\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 4ccc0615331880dedb61515ccd4c7886976f518a\u001B[0m\n",
      "\n",
      "Citations for 4ccc0615: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  60%|\u001B[32m██████    \u001B[0m| 60/100 [02:25<01:02,  1.55s/it]\u001B[32m2026-01-19 15:01:16.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: fcf883a733e8451b96bb69c7cb3fa2937566e2b2\u001B[0m\n",
      "\n",
      "Citations for fcf883a7: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  61%|\u001B[32m██████    \u001B[0m| 61/100 [02:27<00:58,  1.49s/it]\u001B[32m2026-01-19 15:01:17.249\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 853d932e5ee4a2ba52b2a8494415c2a859ab950e\u001B[0m\n",
      "\n",
      "Citations for 853d932e: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  62%|\u001B[32m██████▏   \u001B[0m| 62/100 [02:28<00:58,  1.53s/it]\u001B[32m2026-01-19 15:01:18.859\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 47831eb0acc6c5fe65275361bff8455750b284c2\u001B[0m\n",
      "\n",
      "Citations for 47831eb0: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  63%|\u001B[32m██████▎   \u001B[0m| 63/100 [02:30<01:00,  1.63s/it]\u001B[32m2026-01-19 15:01:20.756\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c1ec7c683213ae8fe0a81a3416f7e256244403f5\u001B[0m\n",
      "\n",
      "Citations for c1ec7c68:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:01:22.442\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 33a0494d034b6efdd5b5ee20188bc84766f6dada\u001B[0m\n",
      "\n",
      "Citations for c1ec7c68: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  6.26it/s]\u001B[A\n",
      "Adding references:  64%|\u001B[32m██████▍   \u001B[0m| 64/100 [02:32<01:00,  1.69s/it]\u001B[32m2026-01-19 15:01:22.539\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 6f4eaaf175f570b42aeea47adc58992fb21a09ad\u001B[0m\n",
      "\n",
      "Citations for 6f4eaaf1: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  65%|\u001B[32m██████▌   \u001B[0m| 65/100 [02:33<00:55,  1.58s/it]\u001B[32m2026-01-19 15:01:23.895\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 92ed7e98bc9462aead5991a5d24b9256e572e4a8\u001B[0m\n",
      "\n",
      "Citations for 92ed7e98: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  66%|\u001B[32m██████▌   \u001B[0m| 66/100 [02:35<00:52,  1.53s/it]\u001B[32m2026-01-19 15:01:25.315\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: f898f7072e69cb3de4f065e6a3ff5ddb954e43c7\u001B[0m\n",
      "\n",
      "Citations for f898f707: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  67%|\u001B[32m██████▋   \u001B[0m| 67/100 [02:36<00:48,  1.46s/it]\u001B[32m2026-01-19 15:01:26.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7a04d5e5f11130d19308bb3c45e4afdb4b5cc1b9\u001B[0m\n",
      "\n",
      "Citations for 7a04d5e5: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  68%|\u001B[32m██████▊   \u001B[0m| 68/100 [02:38<00:46,  1.47s/it]\u001B[32m2026-01-19 15:01:28.099\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: b20da5d8b30d1ef683c9eb5d044ce3f53999352a\u001B[0m\n",
      "\n",
      "Citations for b20da5d8: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  69%|\u001B[32m██████▉   \u001B[0m| 69/100 [02:39<00:43,  1.41s/it]\u001B[32m2026-01-19 15:01:29.409\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 821b9838342bf9ced7efcf381450b895be62bb3c\u001B[0m\n",
      "\n",
      "Citations for 821b9838: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  70%|\u001B[32m███████   \u001B[0m| 70/100 [02:41<00:44,  1.48s/it]\u001B[32m2026-01-19 15:01:31.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 6aab7082a312d9dc2b9a7dc4b6b259006f82f5f1\u001B[0m\n",
      "\n",
      "Citations for 6aab7082: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  71%|\u001B[32m███████   \u001B[0m| 71/100 [02:42<00:43,  1.49s/it]\u001B[32m2026-01-19 15:01:32.527\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 14b3254a560e555c84bcf043665128a4c6e4e4a5\u001B[0m\n",
      "\n",
      "Citations for 14b3254a: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  72%|\u001B[32m███████▏  \u001B[0m| 72/100 [02:43<00:39,  1.41s/it]\u001B[32m2026-01-19 15:01:33.821\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: bd629035a729b3574c44494e62fa6876e202d3c6\u001B[0m\n",
      "\n",
      "Citations for bd629035: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  73%|\u001B[32m███████▎  \u001B[0m| 73/100 [02:45<00:37,  1.38s/it]\u001B[32m2026-01-19 15:01:35.052\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c72013ae6662c39b5d270be2024b2e5aa43b5ec4\u001B[0m\n",
      "\n",
      "Citations for c72013ae: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  74%|\u001B[32m███████▍  \u001B[0m| 74/100 [02:46<00:35,  1.35s/it]\u001B[32m2026-01-19 15:01:36.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 04383296df90d1fdcac124342b633f1fa144ec2e\u001B[0m\n",
      "\n",
      "Citations for 04383296: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  75%|\u001B[32m███████▌  \u001B[0m| 75/100 [02:47<00:33,  1.35s/it]\u001B[32m2026-01-19 15:01:37.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: c4416962fe73647cf6ce559698a621bff6b6428e\u001B[0m\n",
      "\n",
      "Citations for c4416962: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  76%|\u001B[32m███████▌  \u001B[0m| 76/100 [02:49<00:32,  1.34s/it]\u001B[32m2026-01-19 15:01:38.946\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a5dee2ca3cf44a73a56f83465ff58e49f0283869\u001B[0m\n",
      "\n",
      "Citations for a5dee2ca: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  77%|\u001B[32m███████▋  \u001B[0m| 77/100 [02:50<00:29,  1.30s/it]\u001B[32m2026-01-19 15:01:40.266\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 6e64a05db97f8e02c12e68730b9dd582c86f4866\u001B[0m\n",
      "\n",
      "Citations for 6e64a05d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  78%|\u001B[32m███████▊  \u001B[0m| 78/100 [02:51<00:31,  1.41s/it]\u001B[32m2026-01-19 15:01:41.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 017caa25e21a61c736e1a1ec3e02f4b5d127df8e\u001B[0m\n",
      "\n",
      "Citations for 017caa25: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  79%|\u001B[32m███████▉  \u001B[0m| 79/100 [02:53<00:28,  1.38s/it]\u001B[32m2026-01-19 15:01:43.195\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5eacbb2dcbc169b652d7ec967f986283c14f8893\u001B[0m\n",
      "\n",
      "Citations for 5eacbb2d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  80%|\u001B[32m████████  \u001B[0m| 80/100 [02:54<00:26,  1.34s/it]\u001B[32m2026-01-19 15:01:44.447\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: d7463d3ab3c0e009724181492605726e8faf6fba\u001B[0m\n",
      "\n",
      "Citations for d7463d3a:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:01:46.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7553d8932d90cc706f9ac4bf10f184297f4fee23\u001B[0m\n",
      "\n",
      "Citations for d7463d3a: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  6.03it/s]\u001B[A\n",
      "Adding references:  81%|\u001B[32m████████  \u001B[0m| 81/100 [02:56<00:28,  1.48s/it]\u001B[32m2026-01-19 15:01:46.167\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5edce53ca1b8b0579a22e979f18f670c45a37991\u001B[0m\n",
      "\n",
      "Citations for 5edce53c: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  82%|\u001B[32m████████▏ \u001B[0m| 82/100 [02:57<00:25,  1.40s/it]\u001B[32m2026-01-19 15:01:47.527\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: de71fc7d18e4b59ebd875d6e53b5a244335b3987\u001B[0m\n",
      "\n",
      "Citations for de71fc7d: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  83%|\u001B[32m████████▎ \u001B[0m| 83/100 [02:58<00:23,  1.37s/it]\u001B[32m2026-01-19 15:01:48.821\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 7c4168e2ddcefe5671901e5a0d1e70a235133535\u001B[0m\n",
      "\n",
      "Citations for 7c4168e2: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  84%|\u001B[32m████████▍ \u001B[0m| 84/100 [03:00<00:21,  1.37s/it]\u001B[32m2026-01-19 15:01:50.096\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 0aaeb8588fdd8346f4a94e2a94f5d78517fba50a\u001B[0m\n",
      "\n",
      "Citations for 0aaeb858:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:01:52.146\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 9433b842a352645fe0b388ebbb70b7e3931fb447\u001B[0m\n",
      "\n",
      "Citations for 0aaeb858: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  5.43it/s]\u001B[A\n",
      "Adding references:  85%|\u001B[32m████████▌ \u001B[0m| 85/100 [03:02<00:24,  1.60s/it]\u001B[32m2026-01-19 15:01:52.285\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 39122978f55018a9c3d6d721444788fb5f8c6f06\u001B[0m\n",
      "\n",
      "Citations for 39122978:   0%|\u001B[32m          \u001B[0m| 0/1 [00:00<?, ?it/s]\u001B[A\u001B[32m2026-01-19 15:01:54.074\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5931c1d2c1a57b0a05fe38f0b256990e3db62814\u001B[0m\n",
      "\n",
      "Citations for 39122978: 100%|\u001B[32m██████████\u001B[0m| 1/1 [00:00<00:00,  5.11it/s]\u001B[A\n",
      "Adding references:  86%|\u001B[32m████████▌ \u001B[0m| 86/100 [03:04<00:23,  1.70s/it]\u001B[32m2026-01-19 15:01:54.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 5e6d316a1083f1ab79c9ef923b3efef9be166251\u001B[0m\n",
      "\n",
      "Citations for 5e6d316a: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  87%|\u001B[32m████████▋ \u001B[0m| 87/100 [03:05<00:20,  1.58s/it]\u001B[32m2026-01-19 15:01:55.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: fa27da14c99a396a2e570c7555dda0280b16036a\u001B[0m\n",
      "\n",
      "Citations for fa27da14: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  88%|\u001B[32m████████▊ \u001B[0m| 88/100 [03:07<00:20,  1.68s/it]\u001B[32m2026-01-19 15:01:57.449\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 738f0cf67f8178fcefe03806ff5acc9a2dbef015\u001B[0m\n",
      "\n",
      "Citations for 738f0cf6: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  89%|\u001B[32m████████▉ \u001B[0m| 89/100 [03:08<00:17,  1.56s/it]\u001B[32m2026-01-19 15:01:58.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 4d2ff83ff3373c8480144d55684cd34a6376974f\u001B[0m\n",
      "\n",
      "Citations for 4d2ff83f: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  90%|\u001B[32m█████████ \u001B[0m| 90/100 [03:11<00:17,  1.79s/it]\u001B[32m2026-01-19 15:02:01.094\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: 2c1b36b93870279bd675c2973e68354c0cb92fe1\u001B[0m\n",
      "\n",
      "Citations for 2c1b36b9: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  91%|\u001B[32m█████████ \u001B[0m| 91/100 [03:12<00:15,  1.72s/it]\u001B[32m2026-01-19 15:02:02.618\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: a758a71854687fd6921d6561d90238780da4c93b\u001B[0m\n",
      "\n",
      "Citations for a758a718: 0it [00:00, ?it/s]\u001B[A\n",
      "Adding references:  92%|\u001B[32m█████████▏\u001B[0m| 92/100 [03:13<00:12,  1.60s/it]\u001B[32m2026-01-19 15:02:03.985\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.db_neo4j.academic_graph\u001B[0m:\u001B[36madd_paper_from_json\u001B[0m:\u001B[36m69\u001B[0m - \u001B[1mSuccessfully added paper: bcfd982cb5c5216b985cfba4239b9412a1228595\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T20:22:38.410534800Z",
     "start_time": "2026-01-18T19:16:16.038374900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from knowledge_graph_creator.extractors.paper_relation_extractor import PaperRelationExtractor\n",
    "from knowledge_graph_creator.llm import LLMConfig, GroqModel, LLMInference\n",
    "\n",
    "# Initialize LLM client\n",
    "api_key = os.getenv(\"GROP_API_KEY_GRAPH\")\n",
    "llm_config = LLMConfig(model=GroqModel.LLAMA_8B, temperature=0.3)\n",
    "llm_client = LLMInference(api_key=api_key, config=llm_config)\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = PaperRelationExtractor(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USER\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    llm_client=llm_client,\n",
    "    min_delay=1\n",
    ")\n",
    "\n",
    "triplets = extractor.get_non_processed_triplets(min_citation_count=0, head_min_year=2021, tail_min_year=2025)\n",
    "print(f\"Found {len(triplets)} triplets\")  #1709\n",
    "if triplets:\n",
    "    print(\"Sample triplet:\", triplets[0])\n",
    "\n",
    "full_results = extractor.process_all_triplets(min_citation_count=2, head_min_year=2021, tail_min_year=2024)\n",
    "print(f\"Processed {len(full_results)} triplets\")"
   ],
   "id": "6a814bb372feb586",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1709 triplets\n",
      "Sample triplet: {'tail_id': 'b7f9c25c565bf0f7be88d1bb0ccfbad2a61dc018', 'tail_title': 'Enhancing LLM-Based Neural Network Generation: Few-Shot Prompting and Efficient Validation for Automated Architecture Design', 'tail_abstract': 'Automated neural network architecture design remains a significant challenge in computer vision. Task diversity and computational constraints require both effective architectures and efficient search methods. Large Language Models (LLMs) present a promising alternative to computationally intensive Neural Architecture Search (NAS), but their application to architecture generation in computer vision has not been systematically studied, particularly regarding prompt engineering and validation strategies. Building on the task-agnostic NNGPT/LEMUR framework, this work introduces and validates two key contributions for computer vision. First, we present Few-Shot Architecture Prompting (FSAP), the first systematic study of the number of supporting examples (n = 1, 2, 3, 4, 5, 6) for LLM-based architecture generation. We find that using n = 3 examples best balances architectural diversity and context focus for vision tasks. Second, we introduce Whitespace-Normalized Hash Validation, a lightweight deduplication method (less than 1 ms) that provides a 100x speedup over AST parsing and prevents redundant training of duplicate computer vision architectures. In large-scale experiments across seven computer vision benchmarks (MNIST, CIFAR-10, CIFAR-100, CelebA, ImageNette, SVHN, Places365), we generated 1,900 unique architectures. We also introduce a dataset-balanced evaluation methodology to address the challenge of comparing architectures across heterogeneous vision tasks. These contributions provide actionable guidelines for LLM-based architecture search in computer vision and establish rigorous evaluation practices, making automated design more accessible to researchers with limited computational resources.', 'head_id': 'acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269', 'head_title': 'Evaluating Large Language Models Trained on Code', 'head_abstract': 'We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2026-01-19 00:46:17.239\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m152\u001B[0m - \u001B[1mFound 2548 triplets to process\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:17.243\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 1/2548: b7f9c25c565bf0f7be88d1bb0ccfbad2a61dc018 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:20.845\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 2/2548: 07b408f9914248d1e09f6e7d74bc0f049f4e73ea -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:21.915\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency\", \"explanation\": \"Paper 1 reports significantly better performance compared to the method/approach in Paper 2\"}, {\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'Large Language Models (LLMs)\\' which is a concept/method from Paper 2\", \"explanation\": \"Paper 1 depends on the concept of LLMs from Paper 2 as a necessary foundation\"}, {\"type\": \"Enables\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub, which is used in Paper 1\", \"explanation\": \"Paper 2 provides a tool that makes Paper 1\\'s work possible\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 mentions \\'premature convergence and inefficient exploration in high-dimensional code spaces\\' which is a challenge that Paper 2 does not address\", \"explanation\": \"Paper 1 questions the limitations of the approach in Paper 2 without necessarily contradicting its results\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:22.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 3/2548: 85bdbc26b7603f0dc6889b0042ab60e27067fd4e -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:25.494\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 4/2548: 65ad447894127846ee65cec942864984dfc3fbf4 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:33.750\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 5/2548: 1f71c7a089bd3dc89b469e00b66ee4af05caf998 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:46:51.082\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 6/2548: a88a98c480fb2708fef24cf558e528b1fe2419c0 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:47:08.082\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 7/2548: dd8e59be00077496e7541165b03c76f6d6477c58 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:47:25.073\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 8/2548: 94f3235b7ff6ae65e5927822563e4e9b92e50b98 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:47:43.133\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 9/2548: a6f84c5e43de49a7ca2f5a459fd0cc5c6d4c5564 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:48:01.211\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 10/2548: edeae1970cad7fb539ac722f6082ce9c4a874a78 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:48:18.101\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 11/2548: d179bd2b74655c5fd59ec88872f63c1372344c78 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:48:36.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 12/2548: aa7c80569b51da6d0e76f0df73735c81a037d5cc -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:48:54.026\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces the Context-Adaptive Behavior (CAB) Framework, which reveals how behavioral expectations shift along two empirically-derived axes, while Paper 2 focuses on evaluating Large Language Models Trained on Code\", \"explanation\": \"Paper 1 builds upon the evaluation gap identified in Paper 2 and proposes a new framework to address it\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the evaluation gap in AI agent behavior, while Paper 2 evaluates Large Language Models Trained on Code, which is a key aspect of AI agent behavior\", \"explanation\": \"Paper 1 solves a problem left unsolved in Paper 2 by providing a human-centered foundation for designing and evaluating AI agents\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 requires a human-centered approach to evaluate AI agent behavior, which is supported by the findings in Paper 2 on evaluating Large Language Models Trained on Code\", \"explanation\": \"Paper 1 depends on the evaluation methods and findings in Paper 2 to establish a human-centered foundation for AI agent behavior\"}], \"no_relationship_reason\": null}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:48:55.029\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 13/2548: 9e610c651ab2799cecef556d5d788d6dd826bddf -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:49:10.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 14/2548: 9c3a139fba3ed1eae2d25e63a0271fca972654cc -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:49:29.764\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 15/2548: 0c376ff30bb065941b9133e39ffd4790fa95d272 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:49:45.744\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 16/2548: e25840f49ab6799500d439d2619f0cfc15399ac0 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:50:02.296\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 17/2548: 1e4a739236fa6000687b63380e67c7d651924f0f -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:50:20.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 18/2548: 8a664ad7c7bbfd1b90f40bd9270f0b013edcda9d -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:50:39.038\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 19/2548: b0a58b44ece72983ef77d8609388fad424deb246 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:50:55.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 20/2548: b611ceab04f95e747bf5ea9acf14b42cc5ce8b97 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:51:13.149\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 21/2548: 1350c370a1362c5ce1ddfbb9177dab2bd562dcab -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:51:29.979\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 22/2548: e87a68df776ac827028d22bea53239f863e6aa14 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:51:46.935\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 23/2548: 57faa6ba3ed69fdd957aec24d0fda3a943bc9bdc -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:52:05.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 24/2548: dc6a2f95159ebf6c10bbb1505aea5c8dbd6c5cba -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:52:23.737\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 25/2548: ad43ea9bcb091f8e6085becfeeeab1a0ecba0b5f -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:52:40.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 26/2548: 1f8aec6ced8ac067dd8eae6e3b3b80ff47eb9f08 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:52:58.693\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 27/2548: 885ca7596b75a48a0e6f6d73bbe4efdf4dc9e628 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:53:16.641\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 28/2548: 9189365d9485f27187c5e604c553aed26fac83e4 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:53:33.319\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 29/2548: c067966180c3995d38dea27a768794b94ba63809 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:53:50.446\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 30/2548: 5064777b50bdeb4725e9a6e8d5dd113775afa3e7 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:54:07.494\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 31/2548: 8ad8e14d24c9d4cb9988ea1dffa25e6419d57eb3 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:54:24.447\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 32/2548: 6c2717ee6d358e86e23b9a81d18807735d2ccf69 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:54:42.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 33/2548: 4d2e5ac809c751f9e733421385e8b2d298689d78 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:54:59.667\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 34/2548: 8100709956d649d67d6b06e34254728eee17cedb -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:55:17.430\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 35/2548: 5bdde3308d44abe7d85f1705684e2029c84a54d0 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:55:33.987\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces Denoising Entropy, a metric that serves as an internal signal for evaluating generative process, which can be applied to other models, including Codex, a GPT language model fine-tuned on publicly available code from GitHub.\", \"explanation\": \"Paper 1 extends the concept of entropy to masked diffusion models, which can be applied to other models like Codex.\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the challenge of final output quality being highly sensitive to the decoding order, which is also a challenge in generating code.\", \"explanation\": \"Paper 1 solves the problem of decoding order sensitivity, which is also relevant to code generation.\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports that their entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks.\", \"explanation\": \"Paper 1 demonstrates superior performance on code generation tasks compared to other models.\"}, {\"type\": \"Requires\", \"confidence\": \"low\", \"evidence\": \"Paper 1 requires a good understanding of generative models and their limitations, which is also relevant to code generation.\", \"explanation\": \"Paper 1 requires a good understanding of generative models, which is also relevant to code generation.\"}, {\"type\": \"Enables\", \"confidence\": \"low\", \"evidence\": \"Paper 2 provides a GPT language model fine-tuned on publicly available code from GitHub, which can be used to generate code.\", \"explanation\": \"Paper 2 enables the generation of code using a GPT language model.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:55:34.991\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 36/2548: 9aa4aea695d7a40e88ed52d8d666180d6b5faf3f -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:55:51.138\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 37/2548: 883013775853d7b2176feb57be39db10ca3f2677 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:56:08.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 38/2548: ad1237dab39e1687dbe71902721f47f117d63e86 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:56:25.844\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 39/2548: 0169a787573e4efaaa75010779c95556215f6645 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:56:43.816\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 40/2548: 0a7dfc8addff07899a78ff5be218aca606d00379 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:57:00.872\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 41/2548: ba0c969c68ca653bda260369d36e912457ae6909 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:57:17.001\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 operationalizes the transition of Large Language Models from passive tool-users to active workflow architects, which is a concept introduced in Paper 2.\", \"explanation\": \"Paper 1 builds upon the Large Language Model framework presented in Paper 2\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the Discovery Gap, Verification Gap, Decomposition Gap, and Scaling Gap in automated skill generation, which are limitations identified in Paper 2.\", \"explanation\": \"Paper 1 addresses the challenges and limitations presented in Paper 2\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 uses Large Language Models, which are a concept and technology introduced in Paper 2.\", \"explanation\": \"Paper 1 relies on the Large Language Model framework presented in Paper 2 to achieve its goals\"}, {\"type\": \"Enables\", \"confidence\": \"low\", \"evidence\": \"Paper 2 introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub, which is a tool that could be used in the workflow generation process described in Paper 1.\", \"explanation\": \"Paper 2 provides a tool that could be used to support the workflow generation process described in Paper 1\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:57:18.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 42/2548: fdd2e6781d77f24628f6ad06c11306a18a790183 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:57:35.377\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 43/2548: 728fb5189ce89ee3b2640cc0eba4f3cc51b9ff47 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:57:52.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 44/2548: ac4f97b956452b6005664b90a97f54a0ea8ae4ed -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:58:08.496\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub, which is used in Paper 1 for neuron-guided fine-tuning and concept-layer-guided transfer\", \"explanation\": \"Paper 1 relies on the model and dataset introduced in Paper 2 as a necessary foundation for their work\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 provides a GPT language model fine-tuned on code, which Paper 1 uses to demonstrate utility on three tasks: neuron-guided fine-tuning, clone detection, and concept-layer-guided transfer\", \"explanation\": \"Paper 2 provides the tools and methodologies that make Paper 1\\'s work possible\"}, {\"type\": \"Solves\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 addresses the problem of internal interpretability of code LLMs, which is not explicitly mentioned in Paper 2, but the model introduced in Paper 2 can be used to improve interpretability\", \"explanation\": \"Paper 1 addresses a related problem that is not directly solved in Paper 2, but the model introduced in Paper 2 can be used to improve interpretability\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:58:09.501\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 45/2548: 2a09b1865db96efdeca4183ad25257c01775d886 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:58:26.729\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 46/2548: 571360865791c303ce35b8ffa800106f80c7e9ef -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:58:43.932\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'LLMs\\' and \\'code evaluation metrics\\' which are also discussed in Paper 2\", \"explanation\": \"Paper 1 depends on the concepts and methods discussed in Paper 2\"}, {\"type\": \"Challenges\", \"confidence\": \"high\", \"evidence\": \"Paper 1 criticizes existing benchmarks for \\'coarse-grained binary labels\\' and \\'uncontrolled data synthesis methods\\' which is also a limitation discussed in Paper 2\", \"explanation\": \"Paper 1 questions the assumptions and methodology of existing benchmarks, including those discussed in Paper 2\"}, {\"type\": \"Extends\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 proposes a \\'novel perturbation-based framework\\' which can be seen as an extension of the code evaluation methods discussed in Paper 2\", \"explanation\": \"Paper 1 builds upon the concepts and methods discussed in Paper 2 to propose a new framework\"}, {\"type\": \"Solves\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 addresses the limitations of existing benchmarks by proposing a new framework that \\'streamlines the manual annotation procedure\\' and \\'achieves balanced score distributions\\'\", \"explanation\": \"Paper 1 solves a problem left unsolved in Paper 2 by proposing a new framework that addresses its limitations\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:58:44.938\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 47/2548: 10b7c5656f642cb5a3df236ab7a302433dc36198 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:59:02.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 48/2548: fa3fa343eccf90cae47f5dcd1f639e774a8c28c3 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:59:19.339\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs\", \"paper1_abstract\": \"Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM\\'s speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It\"fails fast\"by spending minimal compute in hard-to-speculate regions to shrink speculation latency and\"wins big\"by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\\\times$ speedup over vanilla decoding, 1.7$\\\\times$ over the best naive dLLM drafter, and 2.0$\\\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.\", \"paper2_title\": \"Evaluating Large Language Models Trained on Code\", \"paper2_abstract\": \"We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 00:59:20.342\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 49/2548: 5dcb2c274c8f97f46993ffab1a8848804620c978 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:59:36.470\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 50/2548: 21727373bf6027238cb675724fb0b1c0117d8c16 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 00:59:54.531\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 51/2548: 2b9111eb7c2ca2be922d902a048f3bdaa2dfddf2 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:00:11.289\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 52/2548: 088b175c652b0e6dae85b90d4b05b25d9eb912fc -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:00:27.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 53/2548: a2004ddca9afe4a93b2a1009cafaf13bc0372183 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:00:45.117\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 54/2548: 0899c586ca7c9c8435a4455aacadb33369ada425 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:01:02.277\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"tool call validation failed: parameters for tool RelationshipAnalysis did not match schema: errors: [`/relationships/1`: missing properties: 'explanation']\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'large language models (LLMs) offer new potential for automating and scaling the generation of these checks\\' and Paper 2 introduces \\'Codex, a GPT language model fine-tuned on publicly available code from GitHub\\'\", \"explanation\": \"Paper 1 requires the use of LLMs, which are further developed and applied in Paper 2\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 discusses the potential broader impacts of deploying powerful code generation technologies, including \\'safety, security, and economics\\', which is a key aspect of Paper 1\\'s work on document forgery detection\"}, {\"type\": \"Adapts-from\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 fine-tunes open-source LLMs on structured datasets derived from real-world application scenarios, similar to the approach in Paper 2 where Codex is fine-tuned on publicly available code from GitHub\", \"explanation\": \"Paper 1 adapts the approach from Paper 2 to a different domain, document forgery detection, and uses a similar fine-tuning strategy\"}]} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:01:03.280\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 55/2548: c41e4d4f3dcbd6b865b81e80b1b62e7987eb3d20 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:01:19.327\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 56/2548: 7af10a7b403eeccc0cde2bbb39e1419bed2e7d61 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:01:36.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 57/2548: 6769a7a37909236a9b9a2fb38731e7fb50a8ed34 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:01:54.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 58/2548: b4af5f38acd089da5871a3fa45dba6afac44ef66 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:02:11.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 59/2548: 2aa2d6ebd55027a85607bf68bca9d723fbc2f2eb -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:02:27.134\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning\", \"paper1_abstract\": \"This paper proposes the External Hippocampus framework, which models language model reasoning from a cognitive dynamics perspective as the flow of information energy in semantic space. Unlike traditional weight-space optimization methods, this framework constructs topological cognitive maps through dimensionality reduction projection, enabling precise navigation and intervention of energy flow at test time while avoiding substantial computational requirements and demonstrating predictable intervention patterns. The method effectively addresses the cognitive deadlock problem in multi-step reasoning for small models. Experiments on models<=7B parameters show: map-guided methods achieve 81.20% accuracy on 500 challenging problems (relative baseline +16.80%), reduce reasoning time by>= 15x, with key findings revealing that reasoning stagnation manifests as\"Cognitive Vortex\"and low-entropy potential wells, while temperature perturbations effectively restart energy flow. The framework requires no additional training, possesses autonomous growth capability, and provides an efficient and controllable topological-aware solution for small model reasoning.\", \"paper2_title\": \"Evaluating Large Language Models Trained on Code\", \"paper2_abstract\": \"We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.\"}</function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:02:28.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 60/2548: 278d1529501c9df386f01161795d510e95287273 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:02:43.561\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 61/2548: 03966865097d130afafce247b9fa4cfbac042e60 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:03:00.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 62/2548: b5848c56be606d12b53d53522b792b83452f8025 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:03:17.810\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 63/2548: c0d4447020c422b99f230336c242d4a6e4af0f50 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:03:33.965\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces Propose, Solve, Verify (PSV) a simple self-play framework where formal verification signals are used to create a proposer capable of generating challenging synthetic problems and a solver trained via expert iteration, which is similar to the approach of using a GPT language model fine-tuned on publicly available code from GitHub in Paper 2.\", \"explanation\": \"Paper 1 builds upon the idea of using a language model for code generation presented in Paper 2\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 reports \\'up to 9.6x improvement\\' over inference-only and expert-iteration baselines, while Paper 2 reports \\'28.8% of problems solved\\' on HumanEval, which is a lower percentage.\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the problem of \\'brittle and prone to error propagation\\' rewards based on unit tests in code generation, which is a limitation identified in Paper 2.\", \"explanation\": \"Paper 1 solves a problem left unsolved in Paper 2\"}, {\"type\": \"Requires\", \"confidence\": \"low\", \"evidence\": \"Paper 1 uses formal verification, which is a concept that may be related to the idea of using a language model for code generation in Paper 2.\", \"explanation\": \"Paper 1 may depend on concepts/methods from Paper 2 as a necessary foundation, but the relationship is not explicitly stated\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:03:34.971\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 64/2548: 400e552aa28c680df7d98cf9905f8995d3dfa188 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:03:51.189\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 65/2548: 05df988fe914cdc5401ec7c8d3acad9de15752b1 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:04:08.301\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 66/2548: d793762ff01fb0b0429d683aca88d42c563f3227 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:04:26.378\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 67/2548: dbec3466fd4767fc1e87bddb090ff3194c7a11b1 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:04:43.370\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 68/2548: 24b8a51879945265f7628714b19fcdfc883cfdab -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:05:00.493\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 69/2548: d1ab99980bbee378f446f6b9a1b17ef2e43b6288 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:05:17.323\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 70/2548: 850c2788769053e8642cca549a7bda6b9bce58c7 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:05:33.368\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces a method IPC, an unsupervised framework that leverages Internal Probing of LLMs for Code generation without any external corpus, even unlabeled code snippets, which is a potential extension of the code generation capabilities presented in Paper 2.\", \"explanation\": \"Paper 1 builds upon the code generation framework introduced in Paper 2 by proposing a novel unsupervised approach\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the limitation of requiring extensive labeled or unlabeled datasets for code generation tasks, which is a challenge identified in Paper 2.\", \"explanation\": \"Paper 1 provides a solution to the problem of relying on labeled data for code generation tasks\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports that unsupervised methods can achieve competitive performance compared to supervised approaches, while Paper 2\\'s model solves 28.8% of the problems on HumanEval, which is a relatively low performance compared to Paper 1\\'s unsupervised approach.\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks by achieving competitive results with unsupervised methods\"}, {\"type\": \"Requires\", \"confidence\": \"low\", \"evidence\": \"Paper 1 relies on the internal knowledge and confidence patterns existing in LLMs, which is a concept that may be related to the code generation capabilities presented in Paper 2.\", \"explanation\": \"Paper 1 may depend on the code generation framework introduced in Paper 2 as a necessary foundation for its unsupervised approach\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:05:34.373\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 71/2548: dcc23cede5a4b5ef1f6c9e677fa2be01dbfb5352 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:05:51.605\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 72/2548: 1b086d01d9b9335fed895fc8dbab592ea6644f1e -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:06:08.351\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces a hybrid framework that interleaves SFT and RL within each training instance, building upon the idea of fine-tuning large language models.\", \"explanation\": \"Paper 1 extends the methodology of fine-tuning large language models presented in Paper 2 by introducing a new framework that improves upon it.\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 reports that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.\", \"explanation\": \"Paper 1 demonstrates superior performance compared to the method/approach in Paper 2.\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 mentions the need for stable training, which is achieved through the introduction of Trust-Region SFT (TrSFT).\", \"explanation\": \"Paper 1 requires the concept of stable training, which is addressed in Paper 2 through the use of TrSFT.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:06:09.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 73/2548: ceb4f45d0219876d03de0754d606260bf5a47e31 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:06:25.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 74/2548: ba685629082640917a8f29533fa1e87f6cb8e630 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:06:42.762\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 75/2548: 7483db60e737f8e0a2125d336515d57aa89c8bdd -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:00.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 76/2548: 5055507cbecd8d2aa3c36dceedcdd3c5a0ede102 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:17.732\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"low\", \"evidence\": \"Paper 1 introduces a human-centered benchmark for evaluating prompt-to-app systems, while Paper 2 evaluates large language models trained on code, but there is no direct extension of methodology.\", \"explanation\": \"Paper 1 builds upon the concept of evaluating AI systems, but does not extend the methodology of Paper 2\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the challenge of evaluating prompt-to-app systems, while Paper 2 solves the problem of generating functional code from docstrings.\", \"explanation\": \"Paper 1 and Paper 2 address different but related challenges in AI research\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 shows that Firebase Studio consistently outperforms competing platforms, while Paper 2 shows that Codex solves 28.8% of problems on HumanEval, outperforming GPT-3 and GPT-J.\", \"explanation\": \"Paper 1 and Paper 2 demonstrate the superiority of their respective approaches over existing methods\"}, {\"type\": \"Requires\", \"confidence\": \"low\", \"evidence\": \"Paper 1 does not explicitly require the use of Paper 2\\'s methodology, but Paper 2\\'s results may be used as a benchmark for evaluating prompt-to-app systems.\", \"explanation\": \"Paper 1 and Paper 2 are related but distinct research areas\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2\\'s large language model enables the development of prompt-to-app systems, while Paper 1\\'s benchmark enables the evaluation of these systems.\", \"explanation\": \"Paper 2 provides a tool that makes Paper 1\\'s work possible\"}, {\"type\": \"Achieves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 achieves the goal of developing a human-centered benchmark for evaluating prompt-to-app systems, while Paper 2 achieves the goal of generating functional code from docstrings.\", \"explanation\": \"Paper 1 and Paper 2 successfully implement their respective goals and objectives\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:18.739\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 77/2548: 4cf88bf8f02fdee0b89b85517aa58f819d361f84 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:33.432\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 states that DeepSeek-R1 and GPT-4.1 consistently outperform others in terms of correctness, efficiency, and robustness, while Paper 2 mentions that Codex solves 28.8% of the problems on HumanEval, outperforming GPT-3 and GPT-J.\", \"explanation\": \"Paper 1 reports better performance of specific models compared to the method/approach in Paper 2.\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 emphasizes the importance of \\'careful model selection, effective prompt design, and context-aware usage\\' to ensure reliable code generation, which is a limitation identified in Paper 2.\", \"explanation\": \"Paper 1 depends on the findings and limitations of Paper 2 as a necessary foundation for its work.\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 highlights the critical role of \\'prompt engineering and human oversight\\' in improving results, which could be seen as challenging the assumption of Paper 2 that \\'repeated sampling from the model is a surprisingly effective strategy\\' for producing working solutions.\", \"explanation\": \"Paper 1 questions the assumptions of Paper 2 without necessarily contradicting its results.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:34.437\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 78/2548: ca976e23381d1c65bf47b53f495b9aa39c06d972 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:07:50.431\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 79/2548: 118f3968a66f9e3ec1d013d46a0b30beb1ace810 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:08:09.246\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI\", \"paper1_abstract\": \"The rapidly growing demand for high-quality data in Large Language Models (LLMs) has intensified the need for scalable, reliable, and semantically rich data preparation pipelines. However, current practices remain dominated by ad-hoc scripts and loosely specified workflows, which lack principled abstractions, hinder reproducibility, and offer limited support for model-in-the-loop data generation. To address these challenges, we present DataFlow, a unified and extensible LLM-driven data preparation framework. DataFlow is designed with system-level abstractions that enable modular, reusable, and composable data transformations, and provides a PyTorch-style pipeline construction API for building debuggable and optimizable dataflows. The framework consists of nearly 200 reusable operators and six domain-general pipelines spanning text, mathematical reasoning, code, Text-to-SQL, agentic RAG, and large-scale knowledge extraction. To further improve usability, we introduce DataFlow-Agent, which automatically translates natural-language specifications into executable pipelines via operator synthesis, pipeline planning, and iterative verification. Across six representative use cases, DataFlow consistently improves downstream LLM performance. Our math, code, and text pipelines outperform curated human datasets and specialized synthetic baselines, achieving up to +3\\\\% execution accuracy in Text-to-SQL over SynSQL, +7\\\\% average improvements on code benchmarks, and 1--3 point gains on MATH, GSM8K, and AIME. Moreover, a unified 10K-sample dataset produced by DataFlow enables base models to surpass counterparts trained on 1M Infinity-Instruct data. These results demonstrate that DataFlow provides a practical and high-performance substrate for reliable, reproducible, and scalable LLM data preparation, and establishes a system-level foundation for future data-centric AI development.\", \"paper2_title\": \"Evaluating Large Language Models Trained on Code\", \"paper2_abstract\": \"We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:08:10.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 80/2548: 03962bd0f8d3445b2d6085483f33394f9bce8b19 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:08:25.602\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 81/2548: 6ea989a77ba0d11cff88d204c8c7f3d184f91e88 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:08:42.780\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 82/2548: 64005345fb4713d701fbd67645666553ae225565 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:09:01.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 83/2548: 5a74ca6186acf0ea0582000b722c502e29251e15 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:09:17.141\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'Large Language Models (LLMs) have shown promise in automating code generation\\'\", \"explanation\": \"Paper 1 depends on the concept of LLMs for code generation, which is discussed in Paper 2\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the challenge of \\'mastering parallelism\\' in HPC, while Paper 2 discusses the limitations of LLMs in \\'binding operations to variables\\'\", \"explanation\": \"Paper 1 addresses a problem left unsolved in Paper 2\"}, {\"type\": \"Enables\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 discusses the potential of LLMs in \\'producing working solutions to difficult prompts\\', which is demonstrated in Paper 1\", \"explanation\": \"Paper 2 provides a framework for LLMs that makes Paper 1\\'s work possible\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 questions the effectiveness of LLMs in producing \\'correct and efficient HPC code\\'\", \"explanation\": \"Paper 1 challenges the assumptions made in Paper 2 about the capabilities of LLMs\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:09:18.162\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 84/2548: b232dcaf08dd4953c1d4f9a4e9a6a10a43f7abed -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:09:35.464\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 85/2548: 6f0ecf131ccc0ac9159c4ba4beca9f4c6c5a5702 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:09:52.722\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 86/2548: 86173152d17102a2d2c8d3fefa63bb00db2a640a -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:10:12.395\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 87/2548: e7865c3a2bff295922d50356bd5c89d17f351cf8 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:10:29.246\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 88/2548: ca8a1a81e94af701a91cd40ef4cc72e22ed34143 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:10:47.449\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 89/2548: b8aa44b8e7e62ac1966b3d06b0e56cded1d18647 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:11:05.467\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 90/2548: ab2b748f6db269621afd5a05147f189c955eb35e -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:11:22.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 91/2548: 43e3b82bb3f6d4b6b6dedce5901743ef7cf14790 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:11:39.700\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 92/2548: cd6ed6620434589e36b52f2b2feea19cc79471d1 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:11:57.892\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 93/2548: bcf94ad307cdaea3e72fe64ddf3cb710b1f0ef3a -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:12:16.029\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 94/2548: db28f5750903d8ba9c03ab0cc0696efb7136b7e5 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:12:33.211\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 95/2548: 287064fb4b5586309ca51b1d20322a5c28986093 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:12:50.281\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 surpasses all existing models in both runtime speedup and effective optimization rate on the PIE code performance benchmark\", \"explanation\": \"Paper 1 demonstrates better performance on a specific benchmark compared to existing models\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the limitation of current LLMs in producing high-performance code by introducing PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code\", \"explanation\": \"Paper 1 solves a critical problem left unsolved in Paper 2 by providing a solution to improve code performance\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub, which is used as a prerequisite for Paper 1\\'s work\", \"explanation\": \"Paper 1 depends on the concept of fine-tuning language models on code introduced in Paper 2 as a necessary foundation for its work\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:12:51.283\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 96/2548: 9874f03c03eca5242b92338afe7f0214fe43ef59 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:06.515\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 97/2548: d486078894d089048c973f726afd21e12702005a -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:25.829\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 98/2548: 623511f46cc6270932632362611e3635e376476a -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:41.964\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Adapts-from\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'extending it from text-only regime to multimodal based on the Gemma 3 models\\' while Paper 2 introduces \\'a GPT language model fine-tuned on publicly available code from GitHub\\'\", \"explanation\": \"Paper 1 adapts the approach from Paper 2 to a different domain, multimodal modeling, by building upon the Gemma 3 models\"}, {\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'adapting a pretrained decoder-only model into an encoder-decoder model\\' which is a prerequisite for the work in Paper 2\", \"explanation\": \"Paper 1 requires the concept of adapting a decoder-only model, which is a necessary foundation for the work in Paper 2\"}, {\"type\": \"Enables\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 introduces \\'a GPT language model fine-tuned on publicly available code from GitHub\\' which enables Paper 1\\'s work on multimodal modeling\", \"explanation\": \"Paper 2 provides the necessary tools and frameworks for Paper 1\\'s work on multimodal modeling\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:42.967\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 99/2548: 60a998b87ab15620efeaddcb05a7568d4dea8d40 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:58.948\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Challenges\", \"confidence\": \"high\", \"evidence\": \"Paper 1 reveals a significant performance drop from Easy to Hard problems, which may challenge the assumption that prior evaluations substantially overestimate the reasoning capabilities of LLMs, as Paper 2 discusses the potential broader impacts of deploying powerful code generation technologies, including the risk of overestimating LLMs.\", \"explanation\": \"Paper 1 questions the assumptions and methodology of prior evaluations, which may be related to the discussion in Paper 2 on the potential risks of overestimating LLMs.\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub, which may be used as a prerequisite or foundation for evaluating LLMs, as discussed in Paper 1.\", \"explanation\": \"Paper 2 provides a tool that may be used as a prerequisite for the work in Paper 1.\"}, {\"type\": \"Enables\", \"confidence\": \"low\", \"evidence\": \"Paper 2 discusses the potential broader impacts of deploying powerful code generation technologies, which may enable further research on evaluating LLMs, as discussed in Paper 1.\", \"explanation\": \"Paper 2 may enable further research on evaluating LLMs, but this relationship is not clearly supported by the text.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:13:59.951\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 100/2548: 1fb50c3ba99cf3a8a7bc7b5a7bca30c95841d643 -> acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269\u001B[0m\n",
      "\u001B[32m2026-01-19 01:14:15.512\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 discusses the use of Large Language Models (LLMs) for IaC generation, which is a related concept to the GPT language model fine-tuned on code in Paper 2.\", \"explanation\": \"Paper 1 builds upon the idea of using LLMs for code generation, which is a key concept in Paper 2.\"}, {\"type\": \"Solves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 addresses the problem of low success rates in LLM-based IaC generation, which is a limitation identified in Paper 2.\", \"explanation\": \"Paper 1 provides a solution to the problem of low success rates in LLM-based code generation.\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports an increase in technical validation success from 27.1% to 75.3% and overall success from 27.1% to 62.6% after injecting structured configuration knowledge, while Paper 2 reports a success rate of 28.8% on HumanEval.\", \"explanation\": \"Paper 1 demonstrates better performance on IaC generation tasks compared to the GPT language model fine-tuned on code in Paper 2.\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 mentions a \\'Correctness-Congruence Gap\\' where LLMs can become proficient \\'coders\\' but remain limited \\'architects\\' in fulfilling nuanced user intent, which could be seen as challenging the assumption that LLMs can fully replace human coders.\", \"explanation\": \"Paper 1 raises questions about the limitations of LLMs in code generation.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:14:16.516\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 101/2548: 9c3a139fba3ed1eae2d25e63a0271fca972654cc -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:14:33.059\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 102/2548: b611ceab04f95e747bf5ea9acf14b42cc5ce8b97 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:14:48.895\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 enables a more powerful and practical paradigm of parameter-efficient adaptation, which can be seen as an extension of the parameter-efficient fine-tuning (PEFT) method introduced in Paper 2.\", \"explanation\": \"Paper 1 builds upon the concept of LoRA and proposes a novel training strategy to bridge the gap between linear and non-linear training, making it an extension of the ideas presented in Paper 2.\"}, {\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 relies on the concept of LoRA, which is a widely adopted parameter-efficient fine-tuning (PEFT) method, to propose its novel training strategy.\", \"explanation\": \"Paper 1 depends on the foundation laid by Paper 2 to develop its own approach.\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reduces the performance gap between LoRA and full-parameter training, which can be seen as an improvement over the results presented in Paper 2.\", \"explanation\": \"Paper 1 demonstrates better performance on comparable benchmarks by reducing the gap between LoRA and full-parameter training.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:14:49.898\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 103/2548: ceb4f45d0219876d03de0754d606260bf5a47e31 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:15:07.012\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 104/2548: 634eb3f1a2aae779c6c14d2d87de12926635eb45 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:15:24.824\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 consistently outperforms state-of-the-art approaches across all evaluation metrics, while Paper 2 shows that prompt tuning becomes more competitive with scale, but does not outperform model tuning.\", \"explanation\": \"Paper 1 reports better performance compared to the method/approach in Paper 2.\"}, {\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces the concept of prompt tuning, which is used in Paper 1 to achieve better performance.\", \"explanation\": \"Paper 1 depends on the concept of prompt tuning from Paper 2 as a necessary foundation.\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 provides the concept of prompt tuning, which enables Paper 1 to achieve better performance.\", \"explanation\": \"Paper 2 provides tools that make Paper 1\\'s work possible.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:15:25.827\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 105/2548: b59ff8c4ccc330a1080c355daecc1ae324129992 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:15:41.942\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 106/2548: 13aeb584872d79d295b6cf811b6da9ef78edf195 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:15:59.127\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 discusses the use of frozen language models, which are also used in Paper 1, and Paper 1 highlights the limitations of using static hold-out sets for generative evaluation due to computational constraints.\", \"explanation\": \"Paper 1 requires the use of frozen language models and highlights the challenges of using them in real-world workflows, which is addressed in Paper 2 by introducing prompt tuning.\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces prompt tuning, which enables the efficient reuse of frozen models for multiple downstream tasks, and Paper 1 highlights the need for real-time integration challenges required for production-scale deployment.\", \"explanation\": \"Paper 2 provides a tool that enables the efficient deployment of frozen models, which is a key challenge addressed in Paper 1.\"}, {\"type\": \"Challenges\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 highlights the \\'lab-to-market\\' gap and the challenges of deploying academic prototypes in real-world workflows, while Paper 2 discusses the limitations of GPT-3\\'s few-shot learning and the need for more efficient methods.\", \"explanation\": \"Paper 2 challenges the assumptions of GPT-3\\'s few-shot learning and highlights the need for more efficient methods, which is related to the challenges faced in Paper 1.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:16:00.130\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 107/2548: cc2297bc1a5bea289425e2e363ce266ec93f3183 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:16:15.731\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 108/2548: 7498b5fe096573577653016ea31bffdc1934b1c0 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:16:33.825\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 109/2548: 2dc9e3e2555b215eaab59514367c9b4062794b36 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:16:51.431\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 110/2548: 02ceb7d6c4156af796df1c24acc13c60b5c897f2 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:17:09.760\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 111/2548: b9d59ac26353cf4e3503c115dcf5c2707f41a14d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:17:28.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 112/2548: 3f36e0e6c58b8932711f75df137b18d91ab34ed6 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:17:47.108\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 113/2548: 9d5868c19dffffd280abeb597876f45554d70137 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:18:04.956\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 114/2548: 9b8b5b5e84e37df0852414804558aeae7c50b296 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:18:23.950\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 115/2548: dd702d830b3d0d8c429c25fc36c4782059376d5d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:18:41.820\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 116/2548: 144f2c18086d649a7a25717179a3bea8da209be5 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:19:02.091\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 117/2548: 6eaed634144797607085772294d737650b5b99c0 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:19:18.045\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 118/2548: dc291f73e2e51b01f93a9d543e112ea00de9f38d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:19:36.249\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 119/2548: b9ff9a15f67974f7e0ca325c54e3b336a67d5ccb -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:19:54.547\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 120/2548: 92d79988c765eeedf3baccf572141aa55321cfbb -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:20:12.199\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 121/2548: 012d54b25ae57ca600dce1268054226436f13911 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:20:30.097\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 122/2548: 85ef01c1508b4adf42b53e1f9374d055e6ac9779 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:20:48.896\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 123/2548: d9804fae9e462e87245a0135d853a0ba7048bf0f -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:21:06.946\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 124/2548: 27b90f3ff79b0cac40156eeef5dec0baa74b1919 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:21:24.949\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 125/2548: 749080a05d0cfae4634e74ffcb4fc0f05bbb3a3d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:21:42.995\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 126/2548: 8d84690ce63ed205c8f10ae3a4055f16a5b89986 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:22:00.986\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 127/2548: 8702933dc3abda425bc5d46bec540deb53afa80c -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:22:18.857\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 128/2548: f4976fab1292e714556abf8e142f023b5d696359 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:22:35.778\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 revisits Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and shows that it matches QLoRA\\'s compute scaling slope while cutting peak memory by 50%.\", \"explanation\": \"Paper 1 builds upon and extends the LST technique, improving its efficiency and performance\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA\\'s accuracy on average while being much more memory-efficient.\", \"explanation\": \"Paper 1 demonstrates superior performance and memory efficiency compared to QLoRA\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing.\", \"explanation\": \"Paper 2\\'s work on prompt tuning enables the efficient fine-tuning of large models, which is a key aspect of Paper 1\\'s approach\"}, {\"type\": \"Achieves\", \"confidence\": \"high\", \"evidence\": \"Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.\", \"explanation\": \"Paper 1 achieves the goal of enabling deeper reasoning without additional memory overhead, which is a key objective of Paper 2\\'s work on prompt tuning\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:22:36.781\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 129/2548: 1d852203ca0c2d12d317c4174caf5adfcf710ab2 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:22:54.091\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 130/2548: 45d7debce2afac6c3e10b7399a5eb607ab20f9fe -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:23:13.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 131/2548: 1aec495c9421c93f5c0823a2a7cc0fc34c864ac1 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:23:31.900\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 132/2548: 63d88cedd97ecd215c0e638f3749421674b9947e -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:23:51.468\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 133/2548: 5dcc114383950ad1deda0e4ee5688ff17eb3b77b -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:24:09.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 134/2548: 268189a45a484e1328fb8e8c4f398736720e10ce -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:24:26.389\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces the concept of \\'soft prompts\\' which Paper 1 uses as a necessary foundation for their approach\", \"explanation\": \"Paper 1 relies on the idea of soft prompts presented in Paper 2 to learn universal adversarial suffixes\"}, {\"type\": \"Adapts-from\", \"confidence\": \"high\", \"evidence\": \"Paper 1 applies the concept of \\'soft prompts\\' to a different domain (adversarial suffixes) and problem (reducing accuracy across tasks and models)\", \"explanation\": \"Paper 1 modifies the approach from Paper 2 to suit their specific needs\"}, {\"type\": \"Challenges\", \"confidence\": \"medium\", \"evidence\": \"Paper 1\\'s approach of using universal adversarial suffixes may challenge the assumptions of Paper 2\\'s method of using soft prompts for specific downstream tasks\", \"explanation\": \"Paper 1\\'s findings may question the validity of Paper 2\\'s approach in certain scenarios\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:24:27.392\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 135/2548: 6a95c47a4aabbd9b392bf4db06e89bad1579142c -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:24:43.287\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration\", \"paper1_abstract\": \"With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_\\\\chi$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.\", \"paper2_title\": \"The Power of Scale for Parameter-Efficient Prompt Tuning\", \"paper2_abstract\": \"In this work, we explore “prompt tuning,” a simple yet effective mechanism for learning “soft prompts” to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3’s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method “closes the gap” and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” We release code and model checkpoints to reproduce our experiments.\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:24:44.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 136/2548: aa0f32e0cabc67857ad466e8cc536829bf91c26d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:25:00.495\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 137/2548: 78081516f448d8113a321f109fe6164fa4ae4baa -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:25:19.260\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 138/2548: bf156cc5f29e56ad833618863aed6d7ade69c7c8 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:25:37.533\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 139/2548: c8717ff1077ce1814bf7d288a8f211c86b1c6bfe -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:25:55.378\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 140/2548: 602ab89ec9c6ce3e5b19b8c769fff95a92280e7e -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:26:13.383\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 141/2548: 99221838fd02b78ef3879bf06a23d80a67948bdb -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:26:31.844\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 142/2548: 8c65fd535feda9073dc546df427f41e4f3224a3b -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:26:48.849\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 143/2548: 3f98bca2f500a714ec00f1301035d1244c624038 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:27:06.950\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 144/2548: 123e026135d13869a2b755a6d57d6457b0e77f50 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:27:25.296\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 145/2548: 8286e65cabaf78a95be1fd625dbafff19f5452ba -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:27:44.545\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 146/2548: 07c04eeb5738c46fcfffde487e1ed8f1cab24498 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:02.994\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 147/2548: 280e7f7beed86af49be0679e3638c9971dafce70 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:21.783\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 148/2548: 274c146b420e3777c424bd064fd003911f2ace4d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:39.629\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Adapts-from\", \"confidence\": \"high\", \"evidence\": \"Paper 1 introduces Multi-Scale Visual Prompting (MSVP) for small-image classification, while Paper 2 explores prompt tuning for language models, but both share the idea of incorporating learnable parameters or soft prompts to adapt models.\", \"explanation\": \"Both papers adapt the concept of learnable parameters or soft prompts to improve model performance, but in different domains.\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces the concept of prompt tuning, which enables Paper 1 to explore multi-scale visual prompting for small-image classification.\", \"explanation\": \"Paper 2 provides the necessary tools and methodologies for Paper 1 to build upon.\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports significant improvements in performance across CNN and Vision Transformer backbones, while Paper 2 shows that prompt tuning becomes more competitive with scale and matches the strong performance of model tuning.\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks, but the extent of the improvement is not explicitly stated in the abstracts.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:40.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 149/2548: 9149efc4363f7e8410f72f62ff0e6de8a9525357 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:55.602\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 uses T5, a model also used in Paper 1, and Paper 1 adapts DoLa to FLAN-T5, a variant of T5.\", \"explanation\": \"Paper 1 requires the T5 model, which is also used in Paper 2, to adapt DoLa and examine representation evolution in the decoder.\"}, {\"type\": \"Adapts-from\", \"confidence\": \"high\", \"evidence\": \"Paper 1 adapts DoLa to FLAN-T5, a model also used in Paper 2, to examine representation evolution in the decoder.\", \"explanation\": \"Paper 1 modifies the approach from Paper 2 by adapting DoLa to FLAN-T5 to study representation evolution in the decoder.\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports \\'52% to 99.7%\\' improvement in MemoTrap performance, while Paper 2 focuses on prompt tuning and its benefits.\", \"explanation\": \"Paper 1 demonstrates significant improvement in MemoTrap performance, which is related to the prompt tuning approach discussed in Paper 2.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:28:56.605\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 150/2548: edbae0e935e2c1cc62fa6b6fbda2ac5a544c0667 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:29:12.615\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 151/2548: 369701d126c2575c336ad84428ef90a21dc246a7 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:29:31.399\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 152/2548: d79d08533523b4fedeff2337a0bb3aff12a371ac -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:29:49.388\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 153/2548: 6cb4771076b56673ad54a966635bf585ec641923 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:30:06.563\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 154/2548: 7acb1efd2d692f92d22519add6e54e515c289dfe -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:30:23.424\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 uses parameter-efficient adaptation techniques to translate configuration intents, which is a concept explored in Paper 2.\", \"explanation\": \"Paper 1 builds upon the idea of parameter-efficient adaptation presented in Paper 2.\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 achieves higher syntactic accuracy and goal accuracy than LLM-NetCFG, while Paper 2\\'s method is compared to GPT-3\\'s few-shot learning.\", \"explanation\": \"Paper 1 demonstrates superior performance compared to the method/approach in Paper 2.\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 2 introduces the concept of \\'soft prompts\\' which Paper 1 uses to condition frozen language models.\", \"explanation\": \"Paper 1 depends on the concept of \\'soft prompts\\' presented in Paper 2 as a necessary foundation.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:30:24.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 155/2548: 1a2982bfe03fd287f853c2af8f9b20e98d4824cd -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:30:41.486\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 156/2548: b7fa0bbeca78ab47918e77accdd26cdb03d680a8 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:31:00.516\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 157/2548: 3be1f212f945b512764f0e7f9954df4edc16be76 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:31:19.529\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 158/2548: 9b587e50f15a99647cb4b214f9ef9e41088fff70 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:31:37.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 159/2548: d016a3b0233693d45c1f1d2551728aa2c8f81d91 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:31:55.926\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 160/2548: c1ec7c683213ae8fe0a81a3416f7e256244403f5 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:32:14.284\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 161/2548: db69283c3113cb983fa37fa2e7a8a284b2fbbcd3 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:32:32.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 162/2548: 1283eba4b3796bd2011d7826ec9db668871522d4 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:32:50.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 163/2548: 3bce1be4fb23272e5b272493b9c5615dac43cb81 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:33:08.958\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 164/2548: d6c0dea0e97cb4b69d2e1222441a07e99925d975 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:33:27.098\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 165/2548: 0fe4229308726c39a7944bcf1f0756697118a9e0 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:33:44.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 166/2548: 58ad16a1e4435cd9e9becac470de47f1dd9e1316 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:01.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 167/2548: e28d8590ae5d94dcc3f25a05c28a9e5934a72742 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:19.223\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 proposes a lightweight three-stage training framework that learns a single prompt-specific Behavior-Equivalent token ([BE]) which is a simplification of the recently proposed \\\\u201cprefix tuning\\\\u201d of Li and Liang (2021) and Paper 2 provides a comparison to this and other similar approaches.\", \"explanation\": \"Paper 1 explicitly extends the methodology introduced in Paper 2\"}, {\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 1 requires no access to model internals, no auxiliary compression models, and no labeled responses which is a key aspect of prompt tuning discussed in Paper 2.\", \"explanation\": \"Paper 1 depends on the concepts/methods from Paper 2 as a necessary foundation\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces the concept of soft prompts which enables efficient \\\\u201cprompt ensembling\\\\u201d and Paper 1 builds upon this concept to propose a lightweight three-stage training framework.\", \"explanation\": \"Paper 2 provides tools, frameworks, datasets, or methodologies that make Paper 1\\'s work possible\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:20.226\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 168/2548: 2a330a674d8ef7a6c2bebaa528113d5e2e8978a9 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:35.024\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 discusses the use of frozen language models, while Paper 1 uses DNA foundation models, which are a type of frozen model.\", \"explanation\": \"Paper 1 requires the concept of frozen models, which is discussed in Paper 2.\"}, {\"type\": \"Outperforms\", \"confidence\": \"low\", \"evidence\": \"Paper 1 mentions that mean token embedding consistently and significantly improves sequence classification performance, outperforming other pooling strategies.\", \"explanation\": \"While Paper 1 does not directly compare to Paper 2, it does report improved performance on sequence classification tasks.\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 discusses the limitations of general-purpose DNA foundation models, which could be seen as challenging the idea that frozen models are universally effective.\", \"explanation\": \"Paper 1 raises questions about the limitations of frozen models in certain tasks.\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:36.027\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 169/2548: 4852dd8d9746efa60b2b1f87436c53fa6867d28b -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:34:53.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 170/2548: 359ddd24c36ce879b3851872a90e992911e525c2 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:35:11.018\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 171/2548: 98f13c6a10dc3a73f030fff3ec8a05b7df42f440 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:35:30.074\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 172/2548: b0d112e8742e8925e72e44688d423a8186bdba10 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:35:48.524\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 173/2548: 1f60d646148724894fc7a39c5d2ae0027e6aef77 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:06.391\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 174/2548: 6c8f97f0dbfb37423ddb90075107aba860353d6d -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:22.421\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Requires\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces the concept of \\'prompt tuning\\' which is later used in Paper 1 as a method for reducing the number of trainable parameters\", \"explanation\": \"Paper 1 relies on the methodology introduced in Paper 2 to address the challenge of high computational costs\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 provides the \\'soft prompts\\' approach which Paper 1 uses to achieve parameter-efficient fine-tuning\", \"explanation\": \"Paper 2\\'s approach enables Paper 1 to develop a unified end-to-end benchmark for evaluating diverse PEFT methods\"}, {\"type\": \"Achieves\", \"confidence\": \"high\", \"evidence\": \"Paper 1 successfully implements the goal of reducing the number of trainable parameters while maintaining strong downstream performance\", \"explanation\": \"Paper 1 achieves the objective suggested in Paper 2 of making large language models more accessible\"}, {\"type\": \"Challenges\", \"confidence\": \"low\", \"evidence\": \"Paper 1 questions the assumption that large models are necessary for strong performance by introducing a unified benchmark for evaluating diverse PEFT methods\", \"explanation\": \"Paper 1 challenges the assumption that large models are necessary for strong performance, but does not necessarily contradict the results in Paper 2\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:23.425\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 175/2548: 9698d906e7d8e4f47d5129cfdffdbbaf0f601322 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:39.618\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 176/2548: ac4ccdf870e6ab1c63b890d127d15fba28828bb5 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:57.912\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"ALFedPrompt: Efficient Prompt-Tuning for Privacy-Preserving Sentiment Analysis in Federated Learning\", \"paper1_abstract\": \"Sentiment analysis is important in natural language processing (NLP). It helps organizations gain useful insights from customer feedback, reviews, and social media in areas like marketing and healthcare. While transformer models such as BERT have improved sentiment classification, they require a lot of computing power and memory. This makes it hard to use in environments with limited resources and privacy concerns, like edge devices and decentralized systems. Federated Learning (FL) helps protect privacy by training models locally without sharing raw data; however, traditional FL methods still need large model transfers. This results in high communication and computation costs. To tackle these problems, this paper introduces ALFedPrompt, a lightweight and scalable federated learning framework. ALFedPrompt combines prompt-tuning with the ALBERT model to improve sentiment analysis efficiency. It updates only a small set of task-specific prompt parameters while keeping the ALBERT backbone unchanged. This approach greatly cuts down on communication and computation costs during federated training. ALFedPrompt also takes advantage of ALBERT\\'s lightweight design, which lowers resource use while still providing strong classification performance. Extensive tests on IMDb, Amazon Reviews, and SST-2 datasets show that ALFedPrompt matches or exceeds the accuracy of full fine-tuning methods while staying at a compact size of only $\\\\mathbf{6 0 ~ M B}$. This size allows practical use in real-world federated environments. These findings demonstrate the promise of combining prompttuning with lightweight transformers for privacypreserving, scalable, and efficient sentiment analysis. This approach can lead to the next generation of federated NLP applications.\", \"paper2_title\": \"The Power of Scale for Parameter-Efficient Prompt Tuning\", \"paper2_abstract\": \"In this work, we explore “prompt tuning,” a simple yet effective mechanism for learning “soft prompts” to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3’s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method “closes the gap” and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed “prefix tuning” of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” We release code and model checkpoints to reproduce our experiments.\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:36:58.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 177/2548: 821ad6300fda08ee072c7569b60c85dfac21d1b0 -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:37:15.696\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 178/2548: 366ecaaa518b5d1572c9699e20e2478b8b74befe -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:37:34.840\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 179/2548: a7a651cd1421b42de37c68deda80a78fbce842cf -> ffdbd7f0b03b85747b001b4734d5ee31b5229aa4\u001B[0m\n",
      "\u001B[32m2026-01-19 01:37:52.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 180/2548: 41f3a3879ff3002acb6e91055594c45cebea9988 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:38:11.817\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 181/2548: b59ff8c4ccc330a1080c355daecc1ae324129992 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:38:29.162\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"Task-oriented Learnable Diffusion Timesteps for Universal Few-shot Learning of Dense Tasks\", \"paper1_abstract\": \"Denoising diffusion probabilistic models have brought tremendous advances in generative tasks, achieving state-of-the-art performance thus far. Current diffusion model-based applications exploit the power of learned visual representations from multistep forward-backward Markovian processes for single-task prediction tasks by attaching a task-specific decoder. However, the heuristic selection of diffusion timestep features still heavily relies on empirical intuition, often leading to sub-optimal performance biased towards certain tasks. To alleviate this constraint, we investigate the significance of versatile diffusion timestep features by adaptively selecting timesteps best suited for the few-shot dense prediction task, evaluated on an arbitrary unseen task. To this end, we propose two modules: Task-aware Timestep Selection (TTS) to select ideal diffusion timesteps based on timestep-wise losses and similarity scores, and Timestep Feature Consolidation (TFC) to consolidate the selected timestep features to improve the dense predictive performance in a few-shot setting. Accompanied by our parameter-efficient fine-tuning adapter, our framework effectively achieves superiority in dense prediction performance given only a few support queries. We empirically validate our learnable timestep consolidation method on the large-scale challenging Taskonomy dataset for dense prediction, particularly for practical universal and few-shot learning scenarios.\", \"paper2_title\": \"BEiT: BERT Pre-Training of Image Transformers\", \"paper2_abstract\": \"We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first\"tokenize\"the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup. Moreover, large-size BEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with supervised pre-training on ImageNet-22K (85.2%). The code and pretrained models are available at https://aka.ms/beit.\", \"no_relationship_reason\": null} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:38:30.167\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 182/2548: 4b9605ccb17e6e0726219500538f0de62320b0e8 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:38:47.333\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 183/2548: 6e29cdf2a76ca4a9b51e3a25b7de0836d580fa3a -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:39:05.205\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 184/2548: d4e562fa652ea77479440786a67eed7c9f7468ae -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:39:23.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 185/2548: 4ee2de724d2f2a4dbf7dac9005e952b66dccec9e -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:39:41.264\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 186/2548: 43b775c95ed6a6e012c56ea60c40dea741a10a3e -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:39:59.324\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 187/2548: e3e8cca6a793e617836ade10016d43218cce4ed8 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:40:16.561\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 proposes Unified Autoencoding (UAE), a model that harmonizes semantic structure and pixel details via an innovative frequency-band modulator, enabling their seamless coexistence, which can be seen as extending the transformer architecture introduced in Paper 2\", \"explanation\": \"Paper 1 explicitly extends the methodology introduced in Paper 2 by proposing a new model that builds upon the transformer architecture\"}, {\"type\": \"Outperforms\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 reports state-of-the-art performance on ImageNet and MS-COCO benchmarks, while Paper 2 achieves competitive results with previous pre-training methods\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 provides a pre-trained model that can be fine-tuned for downstream tasks, which enables Paper 1 to achieve state-of-the-art performance on ImageNet and MS-COCO benchmarks\", \"explanation\": \"Paper 2 provides a necessary foundation for Paper 1\\'s work by providing a pre-trained model that can be fine-tuned for downstream tasks\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:40:17.562\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 188/2548: 618b7e7b559f16a82cd6a93999388d4636ca29e7 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:40:34.488\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 189/2548: fc25940bc07b5d47dc93e51a679cb91ec9994cd6 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:40:52.808\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 190/2548: 872f9d35cd60f0bf8187776e51076c5a3f19f5e1 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:41:11.082\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 191/2548: 59b516fcc005062aa7ffc71c0a80269ad83c70ba -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:41:30.317\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 192/2548: 7fb0074a6f1e89d0065c01eeb122fa8c68a9fffa -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:41:48.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 193/2548: fe947fe54a10e1f81c401e603272eb185e65f273 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:42:07.544\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 194/2548: b6b110eebf1e08df852be57b1b141195e69d04a6 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:42:25.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 195/2548: 4b8605c555f6e99c76d7272c415219d16c93c10a -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:42:43.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 196/2548: 0cc7ca03038328f38f8dc8546aab4d2e5e685f62 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:01.853\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"abstracts\": [\"The super-resolution (SR) approach is an effective method for obtaining a hyperspectral (HS) image with high spatial-spectral resolution, which cannot be achieved due to physical limitations. The effectiveness of this method heavily relies on capturing local and non-local self-similarities as well as global spectral correlations. Recently, researchers have utilized Transformers to address the SR issue by leveraging long-range information. However, challenges remain, particularly the computational complexity of self-attention in terms of time and space. By incorporating dynamic masking techniques into the linear Transformer framework, we transform the traditionally quadratic computational demands of Transformers into a more efficient model characterized by sparse and linear complexity. Dynamic masking allows us to create sparse and diverse training images, enabling the model to reduce the complexity associated with self-attention operations while effectively learning a broader range of spatial-spectral features. Furthermore, we convert the cube format of the sparse feature map into a flattened structure using a two-cross four-directional sampling method to assess spatial neighbouring points and gather local information. Conversely, many current SR methods rely on interpolation to upscale low-resolution HS images. However, this technique often results in blurriness and lacks the precision needed to preserve high-quality spatial-spectral details. To address these challenges, we propose a novel dual hierarchical upsampling strategy that incorporates high-frequency details to improve the quality of the SR process. Extensive experiments indicate that our proposed method delivers greater efficiency compared to leading fusion-based SR techniques.\", \"We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first\"tokenize\"the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup. Moreover, large-size BEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with supervised pre-training on ImageNet-22K (85.2%). The code and pretrained models are available at https://aka.ms/beit.\"], \"paper1_title\": \"Dynamic masked transformer with dual-hierarchical upsampling for hyperspectral image super-resolution\", \"paper2_title\": \"BEiT: BERT Pre-Training of Image Transformers\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:02.856\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 197/2548: b3291f32609c92c873ca265e52d6c73ffe8c28f7 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:19.754\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces a self-supervised vision representation model BEiT, which enables Paper 1 to adopt the Masked Autoencoder (MAE) pre-training method, reducing computational overhead during pre-training.\", \"explanation\": \"Paper 2 provides the foundation for Paper 1\\'s efficient decoders with novel structures\"}, {\"type\": \"Adapts-from\", \"confidence\": \"high\", \"evidence\": \"Paper 1 adapts the U-Net architecture from Paper 2\\'s Transformer model to extract multi-scale feature maps and employs Umix-Attention inspired by U-MixFormer to mix hierarchical feature maps.\", \"explanation\": \"Paper 1 modifies and applies the approach from Paper 2 to a different domain, semantic segmentation\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 achieves 80.3% mean Intersection over Union (mIoU) on Cityscapes and 85.5% mIoU on VOC 2012, exceeding the baseline Segmenter by 4% to 5%, while Paper 2 achieves 83.2% top-1 accuracy on ImageNet-1K.\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:20.756\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 198/2548: 6ae2fbff35e1ed3e0f25df86a06b91eb4325f98f -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:37.885\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 199/2548: 028bf92e58e355b05d308604030a191155fe6fc7 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:43:56.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 200/2548: e0cee3927824a33bbcfd96320f8558d980fc7f06 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:44:15.556\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 201/2548: 8dd9931b66db83a60728fb8b51bc90c3ee5da347 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:44:33.442\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 202/2548: bb6b63a11970baa63a27e482467acb894e60dfd8 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:44:51.659\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 203/2548: 3e7cefb2e67bb59a6f8eb5d51b30afb995409add -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:45:09.671\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 204/2548: 11a3d1f15110cae66cf5eed459f17f8d2dc29b45 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:45:29.300\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 205/2548: 84bad4c937f681e98169e873c25fb2fcf0bd4c5d -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:45:47.631\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 206/2548: 24908c010331be64cadffa34f0bf2fd380819e9b -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:46:09.257\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 207/2548: 4fd16df69ec65319e15a117afc5a4949891f5e3b -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:46:27.516\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 208/2548: cc316b251e03e4dd6f16210c916e616fb13c0bbe -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:46:45.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 209/2548: 4484723036545f225ca01aaf79209f814687ec0c -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:47:04.643\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 210/2548: 9d154a131ad501b2eb1913e9f54dd5f36bd15f4f -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:47:22.962\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"Repulsor: Accelerating Generative Modeling with a Contrastive Memory Bank\", \"paper1_abstract\": \"The dominance of denoising generative models (e.g., diffusion, flow-matching) in visual synthesis is tempered by their substantial training costs and inefficiencies in representation learning. While injecting discriminative representations via auxiliary alignment has proven effective, this approach still faces key limitations: the reliance on external, pre-trained encoders introduces overhead and domain shift. A dispersed-based strategy that encourages strong separation among in-batch latent representations alleviates this specific dependency. To assess the effect of the number of negative samples in generative modeling, we propose {\\\\mname}, a plug-and-play training framework that requires no external encoders. Our method integrates a memory bank mechanism that maintains a large, dynamically updated queue of negative samples across training iterations. This decouples the number of negatives from the mini-batch size, providing abundant and high-quality negatives for a contrastive objective without a multiplicative increase in computational cost. A low-dimensional projection head is used to further minimize memory and bandwidth overhead. {\\\\mname} offers three principal advantages: (1) it is self-contained, eliminating dependency on pretrained vision foundation models and their associated forward-pass overhead; (2) it introduces no additional parameters or computational cost during inference; and (3) it enables substantially faster convergence, achieving superior generative quality more efficiently. On ImageNet-256, {\\\\mname} achieves a state-of-the-art FID of \\\\textbf{2.40} within 400k steps, significantly outperforming comparable methods.\", \"paper2_title\": \"BEiT: BERT Pre-Training of Image Transformers\", \"paper2_abstract\": \"We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first\"tokenize\"the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup. Moreover, large-size BEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with supervised pre-training on ImageNet-22K (85.2%). The code and pretrained models are available at https://aka.ms/beit.\"} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:47:24.020\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 211/2548: 45dabaed8b1050c4cc156d13e56c0600aa552043 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:47:39.903\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 212/2548: 1056c2c24478bc151d2e12f6feb93b8cd91fd063 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:47:58.600\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 213/2548: 3e4c628b73a08ce11f043196e381bc518d5ec9d6 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:48:15.731\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"no_relationship_reason\": null, \"relationships\": [{\"type\": \"Extends\", \"confidence\": \"high\", \"evidence\": \"Paper 1 mentions \\'facilitates MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM\\' which is similar to \\'masked image modeling task to pretrain vision Transformers\\' in Paper 2\", \"explanation\": \"Paper 1 extends the masked image modeling approach introduced in Paper 2 to improve visual representation learning in MLLMs\"}, {\"type\": \"Outperforms\", \"confidence\": \"high\", \"evidence\": \"Paper 1 reports \\'extensive experiments across diverse benchmarks prove the superiority of our approach in various scenarios, especially those requiring dense visual capabilities\\' while Paper 2 mentions \\'base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup\\'\", \"explanation\": \"Paper 1 demonstrates superior performance on comparable benchmarks compared to Paper 2\"}, {\"type\": \"Requires\", \"confidence\": \"medium\", \"evidence\": \"Paper 1 mentions \\'the predominant reliance on next-text-token-prediction during training, which fails to provide direct visual supervisory signals\\' which is a limitation addressed by Paper 2\\'s masked image modeling approach\", \"explanation\": \"Paper 1 requires the masked image modeling approach introduced in Paper 2 to address the limitation of next-text-token-prediction during training\"}, {\"type\": \"Enables\", \"confidence\": \"high\", \"evidence\": \"Paper 2 introduces \\'the masked image modeling task to pretrain vision Transformers\\' which enables Paper 1 to \\'facilitate MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM\\'\", \"explanation\": \"Paper 2 provides the necessary framework for Paper 1 to improve visual representation learning in MLLMs\"}]}'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:48:16.735\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 214/2548: 01bd290c0f1a94ca6d2cbbbad959b4e0c8c6afc6 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:48:33.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 215/2548: 8dff2f635b582844edfc4bc9cc66e5907893e903 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:48:51.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 216/2548: ff74cca171ba44c9580063c799a91b2ba2c93777 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:49:09.856\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 217/2548: 17b6a14711297f33d86ba4cb741c596a601e706b -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:49:27.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 218/2548: efa17e17a2a92b5d76c1eb393e822a3d10cb32da -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:49:45.736\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 219/2548: af6d26c5c6ef8b4ad9d36dae3899107f9345d4df -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:50:02.707\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 220/2548: e0064cebf992fedcdb9f67c15dde1957fe9dece8 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:50:20.722\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 221/2548: af6f33f61465e987a9019679f1e54272e5904a78 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:50:38.646\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 222/2548: fa985ea4c4f3565a57eacbd2cea1c41c20d5c67f -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:50:58.285\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 223/2548: 6081af88ebf0d416c353362e650ffc06f9f8eb26 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:51:15.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 224/2548: d82fdb9e395f43d817ca158987e6ac3b51a51470 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:51:32.206\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 225/2548: 5a31a5b8690ae61c29abf8b91b0fdac25e0c817e -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:51:51.530\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 226/2548: c605c7142f2d0d6b8d9305f7a2db238e5dc4f1d0 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:52:11.928\u001B[0m | \u001B[31m\u001B[1mERROR   \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mextract_relation_with_structured_llm\u001B[0m:\u001B[36m100\u001B[0m - \u001B[31m\u001B[1mLLM extraction failed: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=RelationshipAnalysis> {\"paper1_title\": \"InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision\", \"paper1_abstract\": \"Large-scale video-text pretraining achieves strong performance but depends on noisy, synthetic captions with limited semantic coverage, often overlooking implicit world knowledge such as object motion, 3D geometry, and physical cues. In contrast, masked video modeling (MVM) directly exploits spatiotemporal structures but trails text-supervised methods on general tasks. We find this gap arises from overlooked architectural issues: pixel-level reconstruction struggles with convergence and its low-level requirement often conflicts with semantics, while latent prediction often encourages shortcut learning. To address these, we disentangle the traditional encoder-decoder design into an Encoder-Predictor-Decoder (EPD) framework, where the predictor acts as a latent world model, and propose InternVideo-Next, a two-stage pretraining scheme that builds a semantically consistent yet detail-preserving latent space for this world model. First, conventional linear decoder in pixel MVM enforces the predictor output latent to be linearly projected to, thus separable in pixel space, causing the conflict with semantic abstraction. Our Stage 1 proposes a conditional diffusion decoder and injects reliable image-level semantic priors to enhance semantics and convergence, thus bridging pixel-level fidelity with high-level semantic abstraction. Stage 2 further learns world knowledge by predicting frozen Stage 1 targets within this space, mitigating shortcut learning. Trained on public, unlabeled videos, InternVideo-Next achieves state-of-the-art results across benchmarks and provides a scalable path toward general video representation learning.\", \"paper2_title\": \"BEiT: BERT Pre-Training of Image Transformers\", \"paper2_abstract\": \"We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first\"tokenize\"the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup. Moreover, large-size BEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with supervised pre-training on ImageNet-22K (85.2%). The code and pretrained models are available at https://aka.ms/beit.\", \"relationship_types\": [\"Extends\", \"Solves\", \"Outperforms\", \"Validates\", \"Contradicts\", \"Requires\", \"Enables\", \"Adapts-from\", \"Achieves\", \"Challenges\"]} </function>'}}\u001B[0m\n",
      "\u001B[32m2026-01-19 01:52:12.942\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 227/2548: 4accaa1d31ef74444f05957986093ebd3d089a55 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n",
      "\u001B[32m2026-01-19 01:52:26.930\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mknowledge_graph_creator.extractors.paper_relation_extractor\u001B[0m:\u001B[36mprocess_all_triplets\u001B[0m:\u001B[36m165\u001B[0m - \u001B[1mProcessing 228/2548: 7ae636f4092a0056e55f5a7da2f9f1ee150b0127 -> 722ad6ac92286507437b31486f47987d6ece05c9\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2cb6e2c2f6b3714a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
